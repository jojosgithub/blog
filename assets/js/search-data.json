{
  
    
        "post0": {
            "title": "Yule-Simpson's paradox data generator",
            "content": "TOC . write a function for generating Yule-Simpson&#39;s paradox dataset(s) | . For a detailed description of Simpson paradox (and also to see it in a different than usual contest) I suggest to read &quot;Spanos, A. Yule–Simpson’s paradox: the probabilistic versus the empirical conundrum . Stat Methods Appl 30, 605–635 (2021). https://doi.org/10.1007/s10260-020-00536-4&quot; Since this is a just a blog I prefer to show you some plots. First of all we load datasaurus library and then we load the simpson dataset and we plot it with the help of ggplot . obligatory references: . Simpson, E.H. (1951), The Interpretation of Interaction in Contingency Tables. Journal of the Royal Statistical Society: Series B (Methodological), 13: 238-241. https://doi.org/10.1111/j.2517-6161.1951.tb00088.x . G. UNDY YULE, NOTES ON THE THEORY OF ASSOCIATION OF ATTRIBUTES IN STATISTICS, Biometrika, Volume 2, Issue 2, February 1903, Pages 121–134, https://doi.org/10.1093/biomet/2.2.121 . Matejka, J., &amp; Fitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. CHI 2017 Conference proceedings: ACM SIGCHI Conference on Human Factors in Computing Systems. Retrieved from https://www.autodeskresearch.com/publications/samestats. . library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=12, repr.plot.height=8) if(require(ggplot2)){ p &lt;- ggplot(simpsons_paradox, aes(x=x, y=y, colour=dataset))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~dataset, ncol=3) } p + theme_classic(base_size = 20) . what you are seing is (from the description) &quot;A dataset demonstrating Simpson&#39;s Paradox with a strongly positively correlated dataset (simpson_1) and a dataset with the same positive correlation as simpson_1, but where individual groups have a strong negative correlation (simpson_2)&quot;. So is it possible to write a function to create random Yule-Simpson&#39;s paradox dataset? Let&#39;s try it (but first of all we add a regression line as shown in https://stackoverflow.com/a/15654715/6483091 and https://stackoverflow.com/a/37504482/6483091 . library(ggpmisc) method &lt;- y ~ x pp &lt;- ggplot(simpsons_paradox, aes(x= x, y= y, color = dataset)) + geom_point(size=4,alpha=0.55) + facet_wrap(~dataset, ncol=3) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) pp + theme_classic(base_size = 20) . the strategy that we will follow is simple. and it is again very &quot;brutal&quot; and not formal at all. the idea is . create a starting and ending x for the x y dataset we are creating | (add noise) | divide in n intervals/step the xend-xstart | create distributions (normal, uniform, gaussian,whatever) for each step | rotate all the distributions (simple trigonometry) the code is the following, but again plots will better explain the strategy Before implementing the step we try to see how to create a distribution and rotate it | library(data.table) library(foreach) library(ggpmisc) points_dist=100 theta=seq(-1,1,0.1) x &lt;- rnorm(points_dist,0,0.5) y &lt;- rnorm(points_dist,0,0.2) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=3 xstart=1 xend=10 xseq &lt;- seq(xstart,xend,2) yseq &lt;- m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } xysimp &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(xysimp) &lt;- c(&quot;x&quot;,&quot;y&quot;) method &lt;- y ~ x p2 &lt;- ggplot(xysimp, aes(x= x, y= y)) + geom_point(size=1,alpha=0.55) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_classic(base_size = 20) . Error in parse(text = x, srcfile = src): &lt;text&gt;:26:14: unexpected symbol 25: 26: p2 ^ Traceback: . note: I used the base plot since it is was faster for me for prototyping amd inserting it in a loop the trick for creating the colors is taken from https://rjbioinformatics.com/2016/07/10/creating-color-palettes-in-r/ and http://www.colbyimaging.com/wiki/statistics/color-bars. now we are ready to test this snippets to create a simpson plot . ok it seems to work. Let&#39;s wrap it in a function . library(data.table) #we now write everything in form of a function yulsim &lt;- function(m=3,xstart=1,xend=10,theta=-0.3,step=0.5,nfx=0.1,nfy=0.5,npoints=100,coeff=2){ x &lt;- rnorm(npoints,0,nfx) y &lt;- rnorm(npoints,0,nfy) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=m xstart=xstart xend=xend xseq &lt;- seq(xstart,xend,step) yseq &lt;- coeff + m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } ldat &lt;- data.table(xsimp,ysimp) dat &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(dat) &lt;- c(&quot;x&quot;,&quot;y&quot;) my.list &lt;- list(&quot;lout&quot;=ldat,&quot;out&quot;=dat) return(my.list) } . a few more test with ggplot . st1 &lt;- yulsim (m=-3,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) st2 &lt;- yulsim (m=-2,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) ys1 &lt;- st1$out ys2 &lt;- st2$out ys1$set &lt;- &quot;ys_1&quot; ys2$set &lt;- &quot;ys_2&quot; ysset &lt;- rbind(ys1,ys2) p2 &lt;- ggplot(ysset, aes(x=x, y=y, colour=set))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = formula, parse = TRUE, size = 6) p2 + theme_classic(base_size = 22) . and everything seems to work fine. The function is quite brutal, we can indeed change also the distributions used, but it is very flexible and does its job. so now we can generate as much as we want y-s dataset .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Anscombe's  quartet",
            "content": "TOC . can we create a function to recreate infinite Anscombe&#39;s quartet even with more points? | . For a detailed description of Anscombe quartet see, F. J. &quot;Graphs in Statistical Analysis.&quot; The American Statistician 27, no. 1 (1973): 17-21. Accessed July 4, 2021. doi:10.2307/2682899. Let&#39;s start importing the data and plot them also we will add the regression labs . library(ggpmisc) library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=12, repr.plot.height=12) anscombe #rearrange to create a ggplot + regression set1 &lt;- data.frame(anscombe$x1, anscombe$y1) set1$set &lt;- &quot;set1&quot; colnames(set1) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set2 &lt;- data.frame(anscombe$x2, anscombe$y2) set2$set &lt;- &quot;set2&quot; colnames(set2) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set3 &lt;- data.frame(anscombe$x3, anscombe$y3) set3$set &lt;- &quot;set3&quot; colnames(set3) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set4 &lt;- data.frame(anscombe$x4, anscombe$y4) set4$set &lt;- &quot;set4&quot; colnames(set4) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) gganscombe &lt;- rbind(set1,set2,set3,set4) colnames(gganscombe) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) #we need to define the formula before using them in ggsmooth see #https://stackoverflow.com/a/39333833/6483091 formula &lt;- y ~ x p &lt;- ggplot(gganscombe, aes(x= x, y= y, color = set)) + geom_point(alpha = 0.3,size = 4) + facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 6) p+theme_classic(base_size=20) x=gganscombe$x y=gganscombe$y . A data.frame: 11 × 8 x1x2x3x4y1y2y3y4 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 10 | 10 | 10 | 8 | 8.04 | 9.14 | 7.46 | 6.58 | . 8 | 8 | 8 | 8 | 6.95 | 8.14 | 6.77 | 5.76 | . 13 | 13 | 13 | 8 | 7.58 | 8.74 | 12.74 | 7.71 | . 9 | 9 | 9 | 8 | 8.81 | 8.77 | 7.11 | 8.84 | . 11 | 11 | 11 | 8 | 8.33 | 9.26 | 7.81 | 8.47 | . 14 | 14 | 14 | 8 | 9.96 | 8.10 | 8.84 | 7.04 | . 6 | 6 | 6 | 8 | 7.24 | 6.13 | 6.08 | 5.25 | . 4 | 4 | 4 | 19 | 4.26 | 3.10 | 5.39 | 12.50 | . 12 | 12 | 12 | 8 | 10.84 | 9.13 | 8.15 | 5.56 | . 7 | 7 | 7 | 8 | 4.82 | 7.26 | 6.42 | 7.91 | . 5 | 5 | 5 | 8 | 5.68 | 4.74 | 5.73 | 6.89 | . #which trick was used??? #let&#39;s try to rotate a bit the points.. #theta=-1/2 library(foreach) theta &lt;- seq(0,0.13,0.01) a &lt;- foreach(i=1:length(theta)) %do% { gganscombe$xi &lt;- (x*cos(pi*theta[i])-y*sin(pi*theta[i])) gganscombe$yi &lt;- (x*sin(pi*theta[i])-y*cos(pi*theta[i])) #(look also at the error ! essentially perfect fit: summary may be unreliable) p &lt;- ggplot(gganscombe, aes(x= xi, y= yi, color = set)) + geom_point(aes(size = 6),alpha = 0.3) + facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 6) + theme_classic(base_size=20) } a[[1]] a[[6]] a[[14]] . #an example of manually creating a simmetric dataset (look at the R with more points as expected and also compare the stats.. #the secret is all in the simmetry) xn1 &lt;- c(4.28,4.65,5.17, 5.79, 6.17, 6.65, 7.17, 7.70, 8.28, 9.06, 10.11,11.11, 11.90,12.73,13.29, 13.66) yn1 &lt;- c(5.10, 5.29, 5.58, 5.88, 5.35, 6.61, 7.06, 7.44, 7.77, 7.90, 7.94, 7.97, 9.09, 9.51, 9.81, 10.04) datn1 &lt;- data.frame(xn1,yn1) pnew &lt;- ggplot(datn1, aes(x = xn1, y= yn1)) + geom_point(aes(size = 8),alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 8) pnew + theme_classic(base_size=24) summary(datn1) . xn1 yn1 Min. : 4.280 Min. : 5.100 1st Qu.: 6.075 1st Qu.: 5.805 Median : 7.990 Median : 7.605 Mean : 8.607 Mean : 7.396 3rd Qu.:11.307 3rd Qu.: 8.250 Max. :13.660 Max. :10.040 .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "About different data same box plot",
            "content": "TOC . write a function for generating random group of data with (almost) same stats | . As in my previous post I was fascinated by the &quot;datasaurus&quot; (sets of data having same basic stats and also same boxplot). You can have a look at this page to find all details. Since the plot also looks a lot like a kind of diffraction pattern I tried a simple idea I had in mind. What will happen if I generate distributions with as mean the median, q1,q3,min and max of a &quot;reference&quot; dataset and I merge everything together? If I keep the everything &quot;symmetric enough&quot; (I know this is a term that does not exists) cuttin in half the distibution at the min and max I probably will obtain another &quot;equivalent&quot; dataset. . library(data.table) library(ggplot2) library(datasauRus) library(patchwork) library(foreach) summary(box_plots) . left lines normal right Min. :-9.76964 Min. :-9.769575 Min. :-9.76 Min. :-9.760 1st Qu.:-2.68999 1st Qu.:-2.689993 1st Qu.:-2.68 1st Qu.:-2.680 Median :-0.00999 Median :-0.007132 Median : 0.00 Median : 0.000 Mean :-1.17780 Mean :-0.831733 Mean : 0.00 Mean : 1.174 3rd Qu.: 2.67007 3rd Qu.: 2.670236 3rd Qu.: 2.68 3rd Qu.: 2.680 Max. : 9.75025 Max. : 9.756001 Max. : 9.76 Max. : 9.760 split Min. :-9.769886 1st Qu.:-2.689989 Median :-0.003099 Mean :-0.003060 3rd Qu.: 2.680000 Max. : 9.760000 . A simple start . Before creating a function with custom parameters we will start in the most simple way possible . in_dat &lt;- summary(box_plots$left) median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/20 npoints=100 d_median &lt;- rnorm(npoints,median_r,sd_r) d_q1 &lt;- rnorm(npoints,q1_r,sd_r) d_q3 &lt;- rnorm(npoints,q3_r,sd_r) d_min &lt;- rnorm(npoints,min_r,sd_r) d_max &lt;- rnorm(npoints,max_r,sd_r) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; max_r &amp; df_sim$sim&gt;min_r,] options(repr.plot.width=12, repr.plot.height=8) psim &lt;-ggplot(df_sim_sel, aes(x = 0, y = sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=5) + theme_void() + theme(legend.position = &quot;none&quot;) + xlim(-1, 1) bplot &lt;- data.frame(box_plots) p1 &lt;-ggplot(bplot, aes(x = 0, y = left)) + geom_jitter(alpha=0.05,size=5) + theme_void() + theme(legend.position = &quot;none&quot;) + xlim(-1, 1) #summary(df_sim_sel$sim) p1 + psim . so the plot is almost there but the data are still not ok now we create a function, add points and create a bit of benchmarks and also plots.starting with the function . boxSim &lt;- function(npoints,med = median_r, q1 = q1_r, q3 = q3_r, mmin = min_r, mmax = max_r, sdr = c(2,2,2,2,2)) { d_median &lt;- rnorm(npoints,med,sdr[1]) d_q1 &lt;- rnorm(npoints,q1,sdr[2]) d_q3 &lt;- rnorm(npoints,q3,sdr[3]) d_min &lt;- rnorm(npoints,mmin,sdr[4]) d_max &lt;- rnorm(npoints,mmax,sdr[5]) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; mmax &amp; df_sim$sim&gt;mmin,] return(df_sim_sel) } . now everything is more flexible since we can give each of the median,q1,q3,min,max its own variance and create even more combinations (keeping &quot;everything symmetric&quot;) . median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/10 n_points = c(100,1000,50000) t100 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t1k &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t50k &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t100_2 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t1k_2 &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t50k_2 &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) ptest &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + xlim(-1, 3) legend &lt;- cowplot::get_legend(ptest) datr &lt;- data.table(box_plots$left) colnames(datr) &lt;- c(&quot;y&quot;) pref &lt;- ggplot(datr, aes(x = 1, y = y )) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt100 &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt1k &lt;-ggplot(t1k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt50k &lt;-ggplot(t50k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt100_2 &lt;-ggplot(t100_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt1k_2 &lt;-ggplot(t1k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) pt5k_2 &lt;-ggplot(t50k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) library(patchwork) pref + pt1k + pt50k . pb1 &lt;- pref + geom_boxplot(lwd=1, alpha=0.5) pb2 &lt;- ggplot(t100, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.5,,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pb3 &lt;- ggplot(t1k, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.5,,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pb1+pb2+pb3 . refdf &lt;- data.frame(unclass(summary(datr))) colnames(refdf) &lt;- (&quot;refdf&quot;) library(foreach) test &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) res &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res.dat &lt;- data.frame(res) colnames(res.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r1 &lt;- data.frame(refdf,res.dat) test2 &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) res2 &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res2 &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test2[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res2.dat &lt;- data.frame(res2) colnames(res2.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r2 &lt;- data.frame(refdf,res.dat) r1 r2 . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.767939026 | -9.768614806 | -9.769298285 | -9.769536232 | . X.11st Qu.:-2.68999 | -2.686217045 | -2.685360329 | -2.687121153 | -2.690590714 | . X.2Median :-0.00999 | -0.004413976 | -0.009276465 | -0.007803756 | -0.009258504 | . X.3Mean :-1.17780 | 0.044155044 | 0.020435948 | 0.015923968 | -0.011980299 | . X.43rd Qu.: 2.67007 | 2.687758705 | 2.674296672 | 2.674702199 | 2.670794407 | . X.5Max. : 9.75025 | 9.750220137 | 9.748054852 | 9.749136200 | 9.750197901 | . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.767939026 | -9.768614806 | -9.769298285 | -9.769536232 | . X.11st Qu.:-2.68999 | -2.686217045 | -2.685360329 | -2.687121153 | -2.690590714 | . X.2Median :-0.00999 | -0.004413976 | -0.009276465 | -0.007803756 | -0.009258504 | . X.3Mean :-1.17780 | 0.044155044 | 0.020435948 | 0.015923968 | -0.011980299 | . X.43rd Qu.: 2.67007 | 2.687758705 | 2.674296672 | 2.674702199 | 2.670794407 | . X.5Max. : 9.75025 | 9.750220137 | 9.748054852 | 9.749136200 | 9.750197901 | . with this very brutal test we can see that 1000 points are enough to obtain an acceptable random dataset with predefined stats. Also the fun is that changing seeds everytime we have a different dataset.so the mainly advantages are . extremely fast | can generate dataset with same stats as a reference dataset (the generated set can have same number of points &gt; or &lt;) | can several kind of distributions (need to keep data &quot;symmetry&quot;) Probably also this can be a starting point for applying a simulated annealing after. Or this very simple stragegy can be employed for other problems. | .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/samedata.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/samedata.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Recipes for Explodatory Data Analysis by means of simple plots",
            "content": "TOC . how to simulate simple data sets | setup a template for plots | create a line plot | add a jiiter plot to the base plot | increase the dataset dimension for creating a scatter plot | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # loading required libraries for this notebook #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #loading libraries library(ggplot2) library(gridExtra) library(data.table) library(RColorBrewer) library(ggrepel) library(patchwork) . Which plot to choose? . The answer depend on your data. Depending on the kind of relation you would like to highlight there are different plots that can be useful. In my workflow generally the first think I need to check is . presence of a changing in time of one (or multiple) variables | check if the data follow a distribution | check the presence of a linear correlation between the variables | For this purpose we can use . time series plots | distribution plots | correlation plots | First of all we generate some data . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # creating a very simple dataframe #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Parameters x_min &lt;- 0 x_max &lt;- 10 x_step &lt;- 0.01 y_mean &lt;- 0.5 y_sd &lt;- 0.25 y_min &lt;- -1 y_max &lt;- 1 x &lt;- seq(x_min,x_max,x_step) # Variables var_random &lt;- runif(x,y_min,y_max) var_norm &lt;- rnorm(x,y_mean,y_sd) var_sin &lt;- sin(x) # Data.frame df &lt;- data.frame (x,var_random,var_norm,var_sin) dt &lt;- data.table(df) # Melt dtm &lt;- melt(dt, id.vars=&quot;x&quot;) head(dtm) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° . A data.table: 6 × 3 xvariablevalue . &lt;dbl&gt;&lt;fct&gt;&lt;dbl&gt; . 0.00 | var_random | 0.83368080 | . 0.01 | var_random | -0.78873481 | . 0.02 | var_random | 0.10897474 | . 0.03 | var_random | 0.09216935 | . 0.04 | var_random | -0.39577087 | . 0.05 | var_random | -0.28227539 | . notes about the code A few comments on the code. First of all we setup the min of x and y and also a few parameters that will e used to generate the data. as a second step we use the functions runif,rnorm and sin to create a random variable, a uniformly distributed variable and a sinusoid. We use the function data.frame to put togheter the x and vars, we then transform everything in a data.table since we need to use the function melt from the data.table library. In this case the id of each variable corrensponds to the x and so in the melt function we used as a parameter the id.vars=x . Now that we have our data we start plotting them. At first we will setup the general aspect of the plot. We will setup the general aspect of the plot and than add our points. The idea is to create a reusable &quot;template&quot; for all our exploratory data. I love both the basic R plot and ggplot. For this examples we will use ggplot and modify a theme . theme_pub &lt;- function(){ theme_minimal() %+replace% #replace elements we want to change theme( #text elements plot.title = element_text( #title size = 24, #set font size face = &#39;bold&#39;, #bold typeface hjust = 0, #left align vjust = 2), #raise slightly plot.subtitle = element_text( #subtitle size = 24), #font size plot.caption = element_text( #caption size = 24, #font size hjust = 1), #right align axis.title = element_text( #axis titles size = 24), #font size axis.text = element_text( #axis text size = 24), #font size ) } . The previous code create a personalised theme replacing the settings that can be found in the theme_minimal from ggplot. For doing that we use the command %+replace%. We just changed some text options plot, but here you can insert all the customization you want (see the ggplot reference here. Now that we have set the theme for our plot we will plot the three variables. Since we only have 3 variables we can create a line plot for each of the variable and using the library patchwork we put all of the plots together . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Line plot #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° options(repr.plot.width=12, repr.plot.height=8) p &lt;- ggplot(dtm[variable==&quot;var_sin&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable),size=3) + theme_pub() p1 &lt;- ggplot(dtm[variable==&quot;var_norm&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable)) + theme_pub() p2 &lt;- ggplot(dtm[variable==&quot;var_random&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable)) + theme_pub() p p1 p2 . So what does the previous lines of code works. First of all we create an object p. For ggplot every plot is just an object that we can recall later. This is very important since we can put plots in a list, we can write functions that can generate plots and in a few lines and we can take advantage of how R deals with objects also (I&#39;m using the term object with large acception here and not in a stricly language meaaning). We invock a ggplot and we tell that he should consider the data dtm as source for the plot. Since we do not want to plot all the variables we select only the variable_sin. Then we need to specify the x and y and also if we want any grouping variable. Everything included in the parenthesis after the aes() takes care of it. Now the important part: adding a line plot we use the geom_line (if you stop here and try to get a plot you will only get an empty canvas + the x and y axis and labels). This will create the line plot and finally we use the theme for the plot we just created. What does our plots tell us? We can spot without problem the sinusoid. While the other data looks noisy and random. Is there any kind of distribution in the values of our variables? Let&#39;s find it our creating histograms of the values of the variables in exam. . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Histogram plot #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° p3 &lt;- ggplot(dtm[variable==&quot;var_sin&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_pub() p4 &lt;- ggplot(dtm[variable==&quot;var_norm&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_pub() p5 &lt;- ggplot(dtm[variable==&quot;var_random&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_pub() p3 + p4 + p5 . notes on the code. Since dtm is a data.table we can use the following synthax dtm[variable==&quot;var_sin&quot;] to select only the variable we would like to plot. We add an histogram and with the options bins=20,R will take care of splitting the distributions in 20 bins. What do the plots tell us? It is easy to spot at a glance that we have one of the variable with a normal distribution while the other are not. The sin(x) looks as expected with higher frequencies of values at -1 and 1 and the noise variable has does not show any kind of distribution. . Now we will use another kind of plot to see how the data are distributed. What is called a jiiter plot . pj1 &lt;- ggplot(dtm, aes(x=variable,y = value, group=variable)) + geom_jitter(position = position_jitter(0.1),alpha=0.1,, size = 3) + theme_pub() pj1 . notes on the code: in this case we just used all the dataframe with the variable as x and the y as the value. since we have lots of points we used an alpha value of 0.1 in order to have a nice effect on the plot. About the results. the concentration of points (absent in the first case, concentrated on a mean value, at the border for the sinusoidal values) gives us a perfect glance of the distribution of the values. Finally in order to explore Let&#39;s add a second se of &quot;measurements&quot; for each variable to the dataset previously created and let&#39;s plot them . # new variables #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° var_random2 &lt;- runif(x,y_min,y_max) var_norm2 &lt;- rnorm(x,y_mean,y_sd) var_sin2 &lt;- sin(x) + rnorm(x,0,0.01) . At first we will plot them and add them to the previous plot . p7 &lt;- p + geom_line(aes(y=var_sin2, color=&quot;blue&quot;),size=1) p8 &lt;- p1 + geom_line(aes(y=var_norm2, color=&quot;blue&quot;)) p9 &lt;- p2 + geom_line(aes(y=var_random2, color=&quot;blue&quot;)) p7 p8 p9 . we could have changed the dataframe and add the new columns but the versatility of ggplot let us add a new layer of plot and also specify the new color we would like to use for it. Are these &quot;second measurements&quot;s correlated in comparison with the previous one? We can check it using a scatter plot. ggplot can help us with the command geom points but this time for sake of clarity we will first merge the new data with the dataframe . options(repr.plot.width=14, repr.plot.height=7) df2&lt;- data.frame(df,var_sin2,var_norm2,var_random2) dt2 &lt;- data.table(df2) p10 &lt;- ggplot(dt2) + geom_point(aes(x=var_sin,y=var_sin2),size=3) + theme_pub() p11 &lt;- ggplot(dt2) + geom_point(aes(x=var_norm,y=var_norm2),size=3) + theme_pub() p12 &lt;- ggplot(dt2) + geom_point(aes(x=var_random,y=var_random2),size=3)+ theme_pub() p10 p11 p12 . A few notes. We did not use melt since we just needed to select the cols from our newly created dataframe. (If needed a melt data.table can be reshape using the command dcast) We plotted them in pairs because we wanted to see if the &quot;first measurement&quot; was in some way correlated to the &quot;second one&quot; In the first plot we&#39;ve seen the pair of sinusoidal variables. We creaed them as correlated and in fact if we plot one vs the other we can see that the points lie on the bisect of the I and IV quadrant. They are positively lineary correlated. Then we have the norm variables. both of them are created at taking random numbers from a normal distribution. Finally the random vars. totally random and no correlation between them as expected. The aspect of the plot was changed in order to give more space to the plot .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/eda.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/eda.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Simulated Dataset",
            "content": "TOC . writing a function for creating a dataset with a desired number of rows and cols given a mean and an sd (same for all cols) | writing a function for creating a small dataset (n col &lt; 5) with a desired number of rows and cols given a mean and an sd (different for each cols) | writing a function for creating a dataset (n col &gt; 5) with a desired number of rows and cols given a mean and an sd (different for each cols) | writing functions for creating automatic labels for ID and categories | . #°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # loading required libraries for this notebook #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #loading libraries library(ggplot2) library(gridExtra) library(data.table) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Example 1 a very simple test dataset #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # we are creating a dataframe from a matrix obtained replicating x # the desired number_of_cols a vector of length number_of_rows from # a normal distribution rnorm with a mean of my mean and standard deviation as sd number_of_rows &lt;- 7 number_of_cols &lt;- 6 my_mean &lt;- 2 my_sd &lt;- 0.5 newdat &lt;- as.data.frame( replicate( number_of_cols, rnorm(n = number_of_rows, mean = my_mean, sd = my_sd )) ) #in order to print a fancy table newdat . A data.frame: 7 × 6 V1V2V3V4V5V6 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 2.166144 | 2.234508 | 1.626651 | 1.628226 | 1.8127086 | 1.527190 | . 1.775968 | 2.038753 | 1.992165 | 2.595088 | 1.2067000 | 2.231039 | . 3.054668 | 2.092037 | 2.260662 | 1.963266 | 1.8069252 | 1.650384 | . 1.590842 | 1.575725 | 2.410852 | 1.303806 | 0.9177386 | 2.084656 | . 1.796939 | 1.845413 | 1.838408 | 1.938406 | 2.1200911 | 2.051055 | . 2.151737 | 2.221940 | 2.099623 | 1.985790 | 1.7742916 | 2.657077 | . 1.896525 | 1.808077 | 1.279979 | 2.216669 | 1.7692324 | 2.933211 | . note about code: we create a data.frame using replicate to replicate a serie of vectors with normal distributions generated with rnorm . Code for creating small (n col &lt; 5) dataset. Each column has its own mean and sd. In the example reported we have n = 3 (A, B, C) with n row = 50. means are 100,110,120 and sd 1,2,3 | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Ex 2 Another way for a simple dataset #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #in order to obtain ALWAYS same &quot;random&quot; results REMEMBER TO initialize the seed #set.seed(42) number_of_rows &lt;- 5 A &lt;- rnorm( n=number_of_rows, mean=100, sd=1 ) B &lt;- rnorm( n=number_of_rows, mean=110, sd=2 ) C &lt;- rnorm( n=number_of_rows, mean=120, sd=2 ) dat=data.frame(A,B,C) dat . A data.frame: 5 × 3 ABC . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 99.46789 | 105.4446 | 120.8604 | . 99.59229 | 109.9107 | 120.2226 | . 98.89571 | 113.7015 | 121.1714 | . 99.85707 | 108.1090 | 117.6852 | . 101.72180 | 107.9054 | 115.4649 | . same as the one above but more useful for dataset with i columns n col &gt; 5 | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Ex 3 recipes for adding labels #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° number_of_rows = 3 means=c(100, 120, 130, 145) sds=c(10 ,20 ,40 ,10) dat &lt;- lapply( seq(1,length(means)) , function(x) rnorm(number_of_rows,m = means[x], sds[x]) ) dat &lt;- as.data.frame(do.call(cbind, dat)) names_length = 3 dictionary_size &lt;- 10 my_labels &lt;- sort( replicate( length(means), paste(sample(LETTERS[1:dictionary_size], names_length, replace = TRUE), collapse=&quot;&quot;) ) ) my_labels &lt;- unlist(strsplit(my_labels,&quot; &quot;)) colnames(dat) &lt;- my_labels dat . A data.frame: 3 × 4 AEEEJGGCBHJB . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 112.84129 | 134.70014 | 85.59177 | 152.8205 | . 90.87335 | 112.58295 | 120.14683 | 163.0333 | . 110.84161 | 96.70662 | 108.93522 | 145.0431 | . Same as above but shorter | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Ex 4 a variation on recipe 2 #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # building a function for generating data with custom number of rows, means and sds simpleDataset &lt;- function(number_of_rows,means,sds) { l &lt;- length(means) res &lt;- lapply(seq(1:l),function(x) eval( parse(text=paste(&quot;rnorm(&quot;,number_of_rows,&quot;,&quot;,means[x],&quot;,&quot;,sds[x],&quot;)&quot;,sep=&quot;&quot;))) ) dat &lt;- data.frame((sapply(res,c))) id &lt;- rownames(dat) dat &lt;- cbind(id=id,dat) dt &lt;- data.table(dat) return(dt) } dat1 &lt;- simpleDataset(number_of_rows=30, means=c(180,200,205), sds=c(30,20,25)) dat2 &lt;- simpleDataset(number_of_rows=30, means=c(45,50,35), sds=c(2,10,5)) dat &lt;- rbind(dat1,dat2) # rearranging table using melt from data.table dt.melt &lt;- melt(dat, id.vars=&quot;id&quot;) colnames(dt.melt) &lt;- c(&quot;id&quot;,&quot;category&quot;,&quot;var1&quot;) . to create sample names or labels (see https://stackoverflow.com/a/60789938/6483091) | . note on the code: the core line is parse(text=paste(&quot;rnorm(&quot;,number_of_rows,&quot;,&quot;,means[x],&quot;,&quot;,sds[x],&quot;)&quot;,sep=&quot;&quot;))) where we use parse inside the lapply . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # More recipes for labelling #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #short names my_labels &lt;- letters[1:5] my_labels # or &lt;- my_labels &lt;- LETTERS[1:5] my_labels # or arbitrary number of letters using roman letters as in the #function # letters() or LETTERS() dictionary_size &lt;- 7 label_length &lt;- 5 n_replicates &lt;- 3 #random my_labels &lt;- replicate( n_replicates, paste(sample(LETTERS[1:dictionary_size], label_length, replace = TRUE), collapse=&quot;&quot;) ) my_labels #sorted my_labels_sorted &lt;- sort(replicate( n_replicates, paste (sample(LETTERS[1:dictionary_size], label_length, replace = TRUE), collapse=&quot;&quot;) ) ) my_labels_sorted #if you want to mix letters and numbers alfanum_labels &lt;- paste0(rep(LETTERS[1:dictionary_size], each = n_replicates), sep = &quot;-&quot;, 1:n_replicates) alfanum_labels . &lt;ol class=list-inline&gt;&#39;a&#39; | &#39;b&#39; | &#39;c&#39; | &#39;d&#39; | &#39;e&#39; | &lt;/ol&gt; &lt;ol class=list-inline&gt;&#39;A&#39; | &#39;B&#39; | &#39;C&#39; | &#39;D&#39; | &#39;E&#39; | &lt;/ol&gt; &lt;ol class=list-inline&gt;&#39;GBEAF&#39; | &#39;DCEAC&#39; | &#39;FBGDG&#39; | &lt;/ol&gt; &lt;ol class=list-inline&gt;&#39;BGGEB&#39; | &#39;EDBBE&#39; | &#39;GGEBF&#39; | &lt;/ol&gt; &lt;ol class=list-inline&gt;&#39;A-1&#39; | &#39;A-2&#39; | &#39;A-3&#39; | &#39;B-1&#39; | &#39;B-2&#39; | &#39;B-3&#39; | &#39;C-1&#39; | &#39;C-2&#39; | &#39;C-3&#39; | &#39;D-1&#39; | &#39;D-2&#39; | &#39;D-3&#39; | &#39;E-1&#39; | &#39;E-2&#39; | &#39;E-3&#39; | &#39;F-1&#39; | &#39;F-2&#39; | &#39;F-3&#39; | &#39;G-1&#39; | &#39;G-2&#39; | &#39;G-3&#39; | &lt;/ol&gt;",
            "url": "https://jojosgithub.github.io/blog/r/2021/06/18/dataset.html",
            "relUrl": "/r/2021/06/18/dataset.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Don't trust boxplot",
            "content": "TOC . write a function for generating data | use melt for rearranging data | create a base plot | add a boxplot to the base plot | add a jiiter plot to the base plot | create a figure for explaining the box plot (the fun part of this post) | create another dataset | add boxplot + jiiter plot | what&#39;s happening? | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # loading required libraries for this notebook #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #loading libraries library(ggplot2) library(gridExtra) library(data.table) library(RColorBrewer) library(ggpubr) library(rstatix, warn.conflicts = FALSE) library(ggrepel) library(ggpubr) library(patchwork) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # creating a function for generating a dataset #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # function for generating data with custom number of rows, means and sds simpleDataset &lt;- function(number_of_rows,means,sds) { l &lt;- length(means) res &lt;- lapply(seq(1:l),function(x) eval( parse( text=paste(&quot;rnorm(&quot;,number_of_rows,&quot;,&quot;,means[x],&quot;,&quot;,sds[x],&quot;)&quot;,sep=&quot;&quot;)) ) ) dat &lt;- data.frame((sapply(res,c))) id &lt;- rownames(dat) dat &lt;- cbind(id=id,dat) dt &lt;- data.table(dat) return(dt) } dat1 &lt;- simpleDataset(number_of_rows=100, means=runif(10,100,150), sds=runif(10,10,40)) outliers &lt;- simpleDataset(number_of_rows=5, means=runif(10,60,80), sds=runif(10,10,10)) dato &lt;-rbind(dat1,outliers) dt.melt &lt;- melt(dat1, id.vars=&quot;id&quot;) colnames(dt.melt) &lt;- c(&quot;id&quot;,&quot;category&quot;,&quot;var1&quot;) dt.melt$ncat &lt;- as.numeric(dt.melt$category) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Jiitter plots + boxplot + brackets #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #setting up dmiension options(repr.plot.width=8, repr.plot.height=6) #adding jiitter plot p &lt;- ggplot(dt.melt,aes(x=factor(ncat),y=var1)) + geom_jitter(position = position_jitter(0.15),alpha=0.5,size = 3) + geom_boxplot(alpha = 0,lwd=0.2) + theme_minimal(base_size =24) p . So for now everything on track. We created a dataset using a custom function. 10 variables with 100 points each and them we plot them using scatter plots. Before plotting a few more data we need to answer the question How are boxplot constructed? (warning: shameless self-promotion ahead) First of all you can check on my book/ebook https://amzn.com/B08W8W5WSF Now it starts the fun part we will recreate a plot on the anatomy of a boxplot (see here) using ggplot. . # y &lt;- c(60,63,105,155,rnorm(100,80,25)) box &lt;- ggplot() + theme_void() + geom_boxplot(aes(x=0,y=y),width=1,notch = FALSE,lwd=2) + theme(legend.position = &quot;none&quot;) + lims(x=c(-2,2)) #how can we get out data? using the function ggplot_build() #need to change it to a data.frame and rename cols box_data &lt;- (ggplot_build(box)$data)[[1]] box_data bdata &lt;- data.frame(t(box_data[c(1,2,3,4,5,14)])) colnames(bdata) &lt;- c(&quot;y&quot;) #we need to transpose the data and convert them to a data frame #now we extract the ourliers outl &lt;- data.frame(box_data$outliers) colnames(outl) &lt;- c(&quot;outl&quot;) #now that I got the data I plot everything with labels p2 &lt;- box + geom_text (data=bdata,aes( x=1.5, y=y, label = c(&quot;min (no outliers)&quot;,&quot;Lower Q&quot;,&quot;Median&quot;,&quot;Upper Q&quot;,&quot;max&quot;,&quot;outliers&quot;)),size=8) + geom_segment(data=bdata, aes(x = 0.8, y = y, xend = 0.6, yend =y),lwd=1) #since we have created the dataset WITH outliers we include labels also for them #if your dataset has no outliers you need to commet this part out p2 + geom_text_repel(data=outl,aes(x=0.1, y=outl,label=format(round(outl, 2), nsmall = 2)),size=6) . A data.frame: 1 × 26 yminlowermiddleupperymaxoutliersnotchuppernotchlowerxflipped_aes...xidnewxnew_widthweightcolourfillsizealphashapelinetype . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;list&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;lgl&gt;...&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;lgl&gt;&lt;dbl&gt;&lt;chr&gt; . 16.70973 | 63.35951 | 79.60359 | 96.06372 | 136.8562 | 155 | 84.67051 | 74.53667 | 0 | FALSE | ... | 1 | 0 | 1 | 1 | grey20 | white | 2 | NA | 19 | solid | . notes on the code: we create our variable y with rnorm and we add a few outliers by hand then we create the boxplot with an empty theme using theme_void(). The funny part start when we ask ggplot to show how the plot was built with the ggplot_build. We then need to rotate (t) the selected columns c(1,2,3,4,5,14) ,convert the results into a data.frame, rename the columns (colnames) and then use them (our y) to add labvels to our plot using geom_text . So the bound of the box refers to upper and lower quartile. The lower quartile splits off the lowest 25% of the data (also called 25% percentile) while the third quartile splits off the highest 25% of data from the lowest 75% (75% percentile). But what is a quartile? when a set of n measurements of the variable x has been arranged in order of magnitude the pth percentile is the value of x greater than p of the measurements. The 25th and 75th percentile are called the lower and upper quartiles and the 50th percentile is the median of the dataset. the IQR interquartile range (IQR) for a set of measurement is the difference between the upper and lower quartile . Another representation of boxplot can also include notch. the default is not to visualuize them but just adding notch=true to the previous plot we will do the trick . boxnotch &lt;- ggplot() + theme_void() + geom_boxplot(aes(x=0,y=y),width=1,notch = TRUE,lwd=2) + theme(legend.position = &quot;none&quot;) + lims(x=c(-2,4)) notchdata &lt;- data.frame(t(box_data[c(7,8)])) colnames(notchdata) &lt;- c(&quot;y_notch&quot;) #we need to transpose the data and convert them to a data frame #now that I got the data I plot everything with labels p3 &lt;- boxnotch + geom_segment(data=notchdata, aes(x = 0.8, y = mean(y_notch), xend = 0.6, yend = y_notch ),lwd=1) p4 &lt;- p3 + annotate(geom=&quot;text&quot;, x=2.5, y= mean(notchdata$y_notch), label=&quot;notch (95% confidence ninterval of median)&quot;,size=10) p4 . so having a look at the the page we can see that the following case can happen. we will load the dataset from the datasauRus package . What&#39;s happening? . options(repr.plot.width=10, repr.plot.height=10) library(datasauRus) summary(box_plots) p1 &lt;-ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_jitter(alpha=0.05) + theme_void() p2 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values))+ geom_boxplot(lwd=1) + theme_void() p1+p2 . left lines normal right Min. :-9.76964 Min. :-9.769575 Min. :-9.76 Min. :-9.760 1st Qu.:-2.68999 1st Qu.:-2.689993 1st Qu.:-2.68 1st Qu.:-2.680 Median :-0.00999 Median :-0.007132 Median : 0.00 Median : 0.000 Mean :-1.17780 Mean :-0.831733 Mean : 0.00 Mean : 1.174 3rd Qu.: 2.67007 3rd Qu.: 2.670236 3rd Qu.: 2.68 3rd Qu.: 2.680 Max. : 9.75025 Max. : 9.756001 Max. : 9.76 Max. : 9.760 split Min. :-9.769886 1st Qu.:-2.689989 Median :-0.003099 Mean :-0.003060 3rd Qu.: 2.680000 Max. : 9.760000 . Solutions? . We can see that plotting the raw points even for hundreds of points works and represent well our data. In this case adding notch does not solve the problem. Other kind of plot get not fooled by our data as it can be seen in the following figure . options(repr.plot.width=12, repr.plot.height=12) pnotch &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_boxplot(notch=TRUE,lwd=1) + ggtitle(&quot;(notch=TRUE)&quot;) + theme_void() pjitter &lt;-ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_jitter(alpha=0.05) + ggtitle(&quot;geom_jitter&quot;) + theme_void() pviolin &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_violin(lwd=1) + ggtitle(&quot;geom_violin&quot;) + theme_void() pnotch + pjitter + pviolin . Other packages . beeswarm plot ggbeeswarm [https://github.com/eclarke/ggbeeswarm] (and here the things start getting artistic too!) (note: not all representation for this dataset work due to the number of points) | library(ggbeeswarm) p_qrandom0 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05) + ggtitle(&quot;quasi_random&quot;) + theme_void(base_size=20) #p_qrandom0 p_qrandom1 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukey&quot;) + ggtitle(&quot;Tukey&quot;) + theme_void(base_size=20) #p_qrandom1 p_qrandom2 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukeyDense&quot;) + ggtitle(&quot;Tukey + density&quot;) + theme_void(base_size=20) #p_qrandom2 p_qrandom3 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukeyDense&quot;) + ggtitle(&quot;Banded frowns&quot;) + theme_void(base_size=20) #p_qrandom3 p_qrandom4 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;frowney&quot;) + ggtitle(&quot;Banded smiles&quot;) + theme_void(base_size=20) #p_qrandom4 #too many points #p_beeswarm &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + #geom_beeswarm(alpha=0.05) + ggtitle(&quot;beeswarm&quot;) + #theme_void() p_qrandom0 + p_qrandom1+p_qrandom2 . you can halso mix plot a useful package for that is gghalves that you can find here . library(gghalves) point_half &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_half_point(alpha=0.05) +theme_void(base_size=20) violin_half &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_half_violin() +theme_void(base_size=20) point_half + violin_half . finally a very useful package, also my favorite one for EDA ggstatplotthat you can find here that calculate also a lot of useful stats and combine different kind of plot in one plot . library(ggstatsplot) stackbox &lt;- stack(box_plots) pstack &lt;- ggbetweenstats( data = stackbox, x = ind, y = values, ) pstack+ theme(text = element_text(size = 22), plot.subtitle = element_text(size = 20), legend.title = element_text(size = 22), legend.text = element_text(size = 22)) .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/boxplot.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/boxplot.html",
            "date": " • Jun 18, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a researcher at the National Research Council of Italy at the “Giulio Natta” Institute of Chemical Sciences and Technologies (Scitec-Cnr).I started to be interested in multivariate statistics techniques applied to data from physic-chemical analysis methods 15 years ago during my Ph.D. and to apply it to material science ever since. Enthusiast about programming in R and Python in order to write tools for everyday laboratory activities. FOSS advocate. Messy coder. I’ve written also a book on this topic: “Statistical and Multivariate Analysis in Material Science” that you can find here https://amzn.com/B08W8W5WSF .",
          "url": "https://jojosgithub.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jojosgithub.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}