{
  
    
        "post0": {
            "title": "Yule-Simpson's paradox data generator",
            "content": "TOC . write a function for generating Yule-Simpson&#39;s paradox dataset(s) | . For a detailed description of Simpson paradox (and also to see it in a different than usual contest) I suggest to read &quot;Spanos, A. Yule–Simpson’s paradox: the probabilistic versus the empirical conundrum . Stat Methods Appl 30, 605–635 (2021). https://doi.org/10.1007/s10260-020-00536-4&quot; Since this is a just a blog I prefer to show you some plots. First of all we load datasaurus library and then we load the simpson dataset and we plot it with the help of ggplot . obligatory references: . Simpson, E.H. (1951), The Interpretation of Interaction in Contingency Tables. Journal of the Royal Statistical Society: Series B (Methodological), 13: 238-241. https://doi.org/10.1111/j.2517-6161.1951.tb00088.x . G. UNDY YULE, NOTES ON THE THEORY OF ASSOCIATION OF ATTRIBUTES IN STATISTICS, Biometrika, Volume 2, Issue 2, February 1903, Pages 121–134, https://doi.org/10.1093/biomet/2.2.121 . Matejka, J., &amp; Fitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. CHI 2017 Conference proceedings: ACM SIGCHI Conference on Human Factors in Computing Systems. Retrieved from https://www.autodeskresearch.com/publications/samestats. . library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=18.8, repr.plot.height=8.9,units=&quot;cm&quot;) if(require(ggplot2)){ p &lt;- ggplot(simpsons_paradox, aes(x=x, y=y, colour=dataset))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~dataset, ncol=3) } p + theme_light(base_size = 20) . what you are seing is (from the description) &quot;A dataset demonstrating Simpson&#39;s Paradox with a strongly positively correlated dataset (simpson_1) and a dataset with the same positive correlation as simpson_1, but where individual groups have a strong negative correlation (simpson_2)&quot;. So is it possible to write a function to create random Yule-Simpson&#39;s paradox dataset? Let&#39;s try it (but first of all we add a regression line as shown in https://stackoverflow.com/a/15654715/6483091 and https://stackoverflow.com/a/37504482/6483091 . library(ggpmisc) method &lt;- y ~ x pp &lt;- ggplot(simpsons_paradox, aes(x= x, y= y, color = dataset)) + geom_point(size=4,alpha=0.55) + facet_wrap(~dataset, ncol=3) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) pp + theme_light(base_size = 20) . the strategy that we will follow is simple. and it is again very &quot;brutal&quot; and not formal at all. the idea is . create a starting and ending x for the x y dataset we are creating | (add noise) | divide in n intervals/step the xend-xstart | create distributions (normal, uniform, gaussian,whatever) for each step | rotate all the distributions (simple trigonometry) the code is the following, but again plots will better explain the strategy Before implementing the step we try to see how to create a distribution and rotate it | library(data.table) library(foreach) library(ggpmisc) points_dist=50 theta=seq(-1,1,0.1) options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) x &lt;- rnorm(points_dist,0,1) y &lt;- rnorm(points_dist,0,0.2) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=3 xstart=1 xend=10 xseq &lt;- seq(xstart,xend,2) yseq &lt;- m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } xysimp &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(xysimp) &lt;- c(&quot;x&quot;,&quot;y&quot;) method &lt;- y ~ x p2 &lt;- ggplot(xysimp, aes(x= x, y= y)) + geom_point(size=4,alpha=0.55,colour = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, formula = method, color = &quot;red&quot;, size=1, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_light(base_size = 20) . Warning message in x * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in x * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; . ok it seems to work. Let&#39;s wrap it in a function (we also add a set.seed in order to randomize each group) . library(data.table) library(foreach) #we now write everything in form of a function yulsim &lt;- function(m=3,xstart=1,xend=10,theta=-0.3,step=0.5,nfx=0.1,nfy=0.5,npoints=100,coeff=2){ m=m xstart=xstart xend=xend xseq &lt;- seq(xstart,xend,step) yseq &lt;- coeff + m*xseq xsimp &lt;- foreach(i=1:length(xseq)) %do% { set.seed(i*4) x &lt;- rnorm(npoints,0,nfx) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { set.seed(i*3) y &lt;- rnorm(npoints,0,nfy) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) yseq[i]+yi } ldat &lt;- data.table(xsimp,ysimp) dat &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(dat) &lt;- c(&quot;x&quot;,&quot;y&quot;) my.list &lt;- list(&quot;lout&quot;=ldat,&quot;out&quot;=dat) return(my.list) } . a few more test with ggplot . options(repr.plot.width=18.8, repr.plot.height=8.9,units=&quot;cm&quot;) st1 &lt;- yulsim (m=-3,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) st2 &lt;- yulsim (m=-2,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) ys1 &lt;- st1$out ys2 &lt;- st2$out ys1$set &lt;- &quot;ys_1&quot; ys2$set &lt;- &quot;ys_2&quot; ysset &lt;- rbind(ys1,ys2) p2 &lt;- ggplot(ysset, aes(x=x, y=y, colour=set))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_light(base_size = 20) . and everything seems to work fine. The function is quite brutal, we can indeed change also the distributions used, but it is very flexible and does its job. so now we can generate as much as we want y-s dataset .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Yule-Simpson's paradox data generator",
            "content": "TOC . have fun using the package gtrends (https://cran.r-project.org/web/packages/gtrendsR/) | . library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=12, repr.plot.height=8) if(require(ggplot2)){ p &lt;- ggplot(simpsons_paradox, aes(x=x, y=y, colour=dataset))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~dataset, ncol=3) } p + theme_light(base_size = 20) . what you are seing is (from the description) &quot;A dataset demonstrating Simpson&#39;s Paradox with a strongly positively correlated dataset (simpson_1) and a dataset with the same positive correlation as simpson_1, but where individual groups have a strong negative correlation (simpson_2)&quot;. So is it possible to write a function to create random Yule-Simpson&#39;s paradox dataset? Let&#39;s try it (but first of all we add a regression line as shown in https://stackoverflow.com/a/15654715/6483091 and https://stackoverflow.com/a/37504482/6483091 . library(ggpmisc) method &lt;- y ~ x pp &lt;- ggplot(simpsons_paradox, aes(x= x, y= y, color = dataset)) + geom_point(size=4,alpha=0.55) + facet_wrap(~dataset, ncol=3) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) pp + theme_light(base_size = 20) . the strategy that we will follow is simple. and it is again very &quot;brutal&quot; and not formal at all. the idea is . create a starting and ending x for the x y dataset we are creating | (add noise) | divide in n intervals/step the xend-xstart | create distributions (normal, uniform, gaussian,whatever) for each step | rotate all the distributions (simple trigonometry) the code is the following, but again plots will better explain the strategy Before implementing the step we try to see how to create a distribution and rotate it | library(data.table) library(foreach) library(ggpmisc) points_dist=100 theta=seq(-1,1,0.1) x &lt;- rnorm(points_dist,0,0.5) y &lt;- rnorm(points_dist,0,0.2) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=3 xstart=1 xend=10 xseq &lt;- seq(xstart,xend,2) yseq &lt;- m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } xysimp &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(xysimp) &lt;- c(&quot;x&quot;,&quot;y&quot;) method &lt;- y ~ x p2 &lt;- ggplot(xysimp, aes(x= x, y= y)) + geom_point(size=4,alpha=0.15) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_classic(base_size = 20) . Warning message in x * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in x * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; . note: I used the base plot since it is was faster for me for prototyping amd inserting it in a loop the trick for creating the colors is taken from https://rjbioinformatics.com/2016/07/10/creating-color-palettes-in-r/ and http://www.colbyimaging.com/wiki/statistics/color-bars. now we are ready to test this snippets to create a simpson plot . ok it seems to work. Let&#39;s wrap it in a function . library(data.table) #we now write everything in form of a function yulsim &lt;- function(m=3,xstart=1,xend=10,theta=-0.3,step=0.5,nfx=0.1,nfy=0.5,npoints=100,coeff=2){ x &lt;- rnorm(npoints,0,nfx) y &lt;- rnorm(npoints,0,nfy) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=m xstart=xstart xend=xend xseq &lt;- seq(xstart,xend,step) yseq &lt;- coeff + m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } ldat &lt;- data.table(xsimp,ysimp) dat &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(dat) &lt;- c(&quot;x&quot;,&quot;y&quot;) my.list &lt;- list(&quot;lout&quot;=ldat,&quot;out&quot;=dat) return(my.list) } . a few more test with ggplot . st1 &lt;- yulsim (m=-3,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) st2 &lt;- yulsim (m=-2,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) ys1 &lt;- st1$out ys2 &lt;- st2$out ys1$set &lt;- &quot;ys_1&quot; ys2$set &lt;- &quot;ys_2&quot; ysset &lt;- rbind(ys1,ys2) p2 &lt;- ggplot(ysset, aes(x=x, y=y, colour=set))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = formula, parse = TRUE, size = 6) p2 + theme_classic(base_size = 22) . and everything seems to work fine. The function is quite brutal, we can indeed change also the distributions used, but it is very flexible and does its job. so now we can generate as much as we want y-s dataset .",
            "url": "https://jojosgithub.github.io/blog/r/google/trends/2021/07/04/trends.html",
            "relUrl": "/r/google/trends/2021/07/04/trends.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Anscombe's  quartet",
            "content": "TOC . can we create a function to recreate infinite Anscombe&#39;s quartet even with more points? | . For a detailed description of Anscombe quartet see, F. J. &quot;Graphs in Statistical Analysis.&quot; The American Statistician 27, no. 1 (1973): 17-21. Accessed July 4, 2021. doi:10.2307/2682899. Let&#39;s start importing the data and plot them also we will add the regression labs . library(ggpmisc) library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) anscombe #rearrange to create a ggplot + regression set1 &lt;- data.frame(anscombe$x1, anscombe$y1) set1$set &lt;- &quot;set1&quot; colnames(set1) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set2 &lt;- data.frame(anscombe$x2, anscombe$y2) set2$set &lt;- &quot;set2&quot; colnames(set2) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set3 &lt;- data.frame(anscombe$x3, anscombe$y3) set3$set &lt;- &quot;set3&quot; colnames(set3) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) set4 &lt;- data.frame(anscombe$x4, anscombe$y4) set4$set &lt;- &quot;set4&quot; colnames(set4) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) gganscombe &lt;- rbind(set1,set2,set3,set4) colnames(gganscombe) &lt;- c(&quot;x&quot;,&quot;y&quot;,&quot;set&quot;) #we need to define the formula before using them in ggsmooth see #https://stackoverflow.com/a/39333833/6483091 formula &lt;- y ~ x p &lt;- ggplot(gganscombe, aes(x= x, y= y, color = set)) + geom_point(alpha = 0.3,size = 4) + facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 6) p+theme_light(base_size=20) x=gganscombe$x y=gganscombe$y . A data.frame: 11 × 8 x1x2x3x4y1y2y3y4 . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . 10 | 10 | 10 | 8 | 8.04 | 9.14 | 7.46 | 6.58 | . 8 | 8 | 8 | 8 | 6.95 | 8.14 | 6.77 | 5.76 | . 13 | 13 | 13 | 8 | 7.58 | 8.74 | 12.74 | 7.71 | . 9 | 9 | 9 | 8 | 8.81 | 8.77 | 7.11 | 8.84 | . 11 | 11 | 11 | 8 | 8.33 | 9.26 | 7.81 | 8.47 | . 14 | 14 | 14 | 8 | 9.96 | 8.10 | 8.84 | 7.04 | . 6 | 6 | 6 | 8 | 7.24 | 6.13 | 6.08 | 5.25 | . 4 | 4 | 4 | 19 | 4.26 | 3.10 | 5.39 | 12.50 | . 12 | 12 | 12 | 8 | 10.84 | 9.13 | 8.15 | 5.56 | . 7 | 7 | 7 | 8 | 4.82 | 7.26 | 6.42 | 7.91 | . 5 | 5 | 5 | 8 | 5.68 | 4.74 | 5.73 | 6.89 | . #which trick was used??? #let&#39;s try to rotate a bit the points.. #theta=-1/2 library(foreach) theta &lt;- seq(0,0.13,0.01) a &lt;- foreach(i=1:length(theta)) %do% { gganscombe$xi &lt;- (x*cos(pi*theta[i])-y*sin(pi*theta[i])) gganscombe$yi &lt;- (x*sin(pi*theta[i])-y*cos(pi*theta[i])) #(look also at the error ! essentially perfect fit: summary may be unreliable) p &lt;- ggplot(gganscombe, aes(x= xi, y= yi, color = set)) + geom_point(aes(size = 6),alpha = 0.3) + facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 6) + theme_light(base_size=20) } a[[1]] a[[6]] a[[14]] . #an example of manually creating a simmetric dataset (look at the R with more points as expected and also compare the stats.. #the secret is all in the simmetry) xn1 &lt;- c(4.28,4.65,5.17, 5.79, 6.17, 6.65, 7.17, 7.70, 8.28, 9.06, 10.11,11.11, 11.90,12.73,13.29, 13.66) yn1 &lt;- c(5.10, 5.29, 5.58, 5.88, 5.35, 6.61, 7.06, 7.44, 7.77, 7.90, 7.94, 7.97, 9.09, 9.51, 9.81, 10.04) datn1 &lt;- data.frame(xn1,yn1) pnew &lt;- ggplot(datn1, aes(x = xn1, y= yn1)) + geom_point(aes(size = 8),alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = 0.15, formula = formula, parse = TRUE, size = 8) pnew + theme_light(base_size=20) summary(datn1) . xn1 yn1 Min. : 4.280 Min. : 5.100 1st Qu.: 6.075 1st Qu.: 5.805 Median : 7.990 Median : 7.605 Mean : 8.607 Mean : 7.396 3rd Qu.:11.307 3rd Qu.: 8.250 Max. :13.660 Max. :10.040 .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "About different data same box plot",
            "content": "TOC . write a function for generating random group of data with (almost) same stats | . As in my previous post I was fascinated by the &quot;datasaurus&quot; (sets of data having same basic stats and also same boxplot). You can have a look at this page to find all details. Since the plot also looks a lot like a kind of diffraction pattern I tried a simple idea I had in mind. What will happen if I generate distributions with as mean the median, q1,q3,min and max of a &quot;reference&quot; dataset and I merge everything together? If I keep the everything &quot;symmetric enough&quot; (I know this is a term that does not exists) cuttin in half the distibution at the min and max I probably will obtain another &quot;equivalent&quot; dataset. . library(data.table) library(ggplot2) library(datasauRus) library(patchwork) library(foreach) summary(box_plots) . left lines normal right Min. :-9.76964 Min. :-9.769575 Min. :-9.76 Min. :-9.760 1st Qu.:-2.68999 1st Qu.:-2.689993 1st Qu.:-2.68 1st Qu.:-2.680 Median :-0.00999 Median :-0.007132 Median : 0.00 Median : 0.000 Mean :-1.17780 Mean :-0.831733 Mean : 0.00 Mean : 1.174 3rd Qu.: 2.67007 3rd Qu.: 2.670236 3rd Qu.: 2.68 3rd Qu.: 2.680 Max. : 9.75025 Max. : 9.756001 Max. : 9.76 Max. : 9.760 split Min. :-9.769886 1st Qu.:-2.689989 Median :-0.003099 Mean :-0.003060 3rd Qu.: 2.680000 Max. : 9.760000 . A simple start . Before creating a function with custom parameters we will start in the most simple way possible . in_dat &lt;- summary(box_plots$left) median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/20 npoints=100 d_median &lt;- rnorm(npoints,median_r,sd_r) d_q1 &lt;- rnorm(npoints,q1_r,sd_r) d_q3 &lt;- rnorm(npoints,q3_r,sd_r) d_min &lt;- rnorm(npoints,min_r,sd_r) d_max &lt;- rnorm(npoints,max_r,sd_r) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; max_r &amp; df_sim$sim&gt;min_r,] options(repr.plot.width=12, repr.plot.height=8) psim &lt;-ggplot(df_sim_sel, aes(x = 0, y = sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=5) + theme_void() + theme(legend.position = &quot;none&quot;) + xlim(-1, 1) bplot &lt;- data.frame(box_plots) p1 &lt;-ggplot(bplot, aes(x = 0, y = left)) + geom_jitter(alpha=0.05,size=5) + theme_void() + theme(legend.position = &quot;none&quot;) + xlim(-1, 1) #summary(df_sim_sel$sim) p1 + psim . so the plot is almost there but the data are still not ok now we create a function, add points and create a bit of benchmarks and also plots.starting with the function . boxSim &lt;- function(npoints,med = median_r, q1 = q1_r, q3 = q3_r, mmin = min_r, mmax = max_r, sdr = c(2,2,2,2,2)) { d_median &lt;- rnorm(npoints,med,sdr[1]) d_q1 &lt;- rnorm(npoints,q1,sdr[2]) d_q3 &lt;- rnorm(npoints,q3,sdr[3]) d_min &lt;- rnorm(npoints,mmin,sdr[4]) d_max &lt;- rnorm(npoints,mmax,sdr[5]) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; mmax &amp; df_sim$sim&gt;mmin,] return(df_sim_sel) } . now everything is more flexible since we can give each of the median,q1,q3,min,max its own variance and create even more combinations (keeping &quot;everything symmetric&quot;) . median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/10 n_points = c(100,1000,50000) t100 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t1k &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t50k &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t100_2 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t1k_2 &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t50k_2 &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) ptest &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + xlim(-1, 3) legend &lt;- cowplot::get_legend(ptest) datr &lt;- data.table(box_plots$left) colnames(datr) &lt;- c(&quot;y&quot;) pref &lt;- ggplot(datr, aes(x = 1, y = y )) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt100 &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt1k &lt;-ggplot(t1k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt50k &lt;-ggplot(t50k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt100_2 &lt;-ggplot(t100_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt1k_2 &lt;-ggplot(t1k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pt5k_2 &lt;-ggplot(t50k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + theme(legend.position = &quot;none&quot;) library(patchwork) pref + pt1k + pt50k . pb1 &lt;- pref + geom_boxplot(lwd=1, alpha=0.5) pb2 &lt;- ggplot(t100, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.5,,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pb3 &lt;- ggplot(t1k, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.5,,size=3) + theme_void() + theme(legend.position = &quot;none&quot;) pb1+pb2+pb3 . refdf &lt;- data.frame(unclass(summary(datr))) colnames(refdf) &lt;- (&quot;refdf&quot;) library(foreach) test &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) res &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res.dat &lt;- data.frame(res) colnames(res.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r1 &lt;- data.frame(refdf,res.dat) test2 &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) res2 &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res2 &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test2[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res2.dat &lt;- data.frame(res2) colnames(res2.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r2 &lt;- data.frame(refdf,res.dat) r1 r2 . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.764759795 | -9.76911275 | -9.76934841 | -9.769138681 | . X.11st Qu.:-2.68999 | -2.674497906 | -2.69465408 | -2.69012231 | -2.689882212 | . X.2Median :-0.00999 | -0.009233695 | -0.01048241 | -0.01190076 | -0.008416714 | . X.3Mean :-1.17780 | 0.038431779 | -0.04518597 | -0.01815146 | 0.010799885 | . X.43rd Qu.: 2.67007 | 2.679063567 | 2.66006345 | 2.67252556 | 2.674577773 | . X.5Max. : 9.75025 | 9.743753597 | 9.74994685 | 9.75018028 | 9.748940220 | . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.764759795 | -9.76911275 | -9.76934841 | -9.769138681 | . X.11st Qu.:-2.68999 | -2.674497906 | -2.69465408 | -2.69012231 | -2.689882212 | . X.2Median :-0.00999 | -0.009233695 | -0.01048241 | -0.01190076 | -0.008416714 | . X.3Mean :-1.17780 | 0.038431779 | -0.04518597 | -0.01815146 | 0.010799885 | . X.43rd Qu.: 2.67007 | 2.679063567 | 2.66006345 | 2.67252556 | 2.674577773 | . X.5Max. : 9.75025 | 9.743753597 | 9.74994685 | 9.75018028 | 9.748940220 | . with this very brutal test we can see that 1000 points are enough to obtain an acceptable random dataset with predefined stats. Also the fun is that changing seeds everytime we have a different dataset.so the mainly advantages are . extremely fast | can generate dataset with same stats as a reference dataset (the generated set can have same number of points &gt; or &lt;) | can several kind of distributions (need to keep data &quot;symmetry&quot;) Probably also this can be a starting point for applying a simulated annealing after. Or this very simple stragegy can be employed for other problems. | .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/samedata.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/samedata.html",
            "date": " • Jun 18, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a researcher at the National Research Council of Italy at the “Giulio Natta” Institute of Chemical Sciences and Technologies (Scitec-Cnr).I started to be interested in multivariate statistics techniques applied to data from physic-chemical analysis methods 15 years ago during my Ph.D. and to apply it to material science ever since. Enthusiast about programming in R and Python in order to write tools for everyday laboratory activities. FOSS advocate. Messy coder. I’ve written also a book on this topic: “Statistical and Multivariate Analysis in Material Science” that you can find here https://amzn.com/B08W8W5WSF .",
          "url": "https://jojosgithub.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jojosgithub.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}