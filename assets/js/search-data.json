{
  
    
        "post0": {
            "title": "Yule-Simpson's paradox data generator",
            "content": "TOC . write a function for generating Yule-Simpson&#39;s paradox dataset(s) | . For a detailed description of Simpson paradox (and also to see it in a different than usual contest) I suggest to read &quot;Spanos, A. Yule–Simpson’s paradox: the probabilistic versus the empirical conundrum . Stat Methods Appl 30, 605–635 (2021). https://doi.org/10.1007/s10260-020-00536-4&quot; Since this is a just a blog I prefer to show you some plots. First of all we load datasaurus library and then we load the simpson dataset and we plot it with the help of ggplot . obligatory references: . Simpson, E.H. (1951), The Interpretation of Interaction in Contingency Tables. Journal of the Royal Statistical Society: Series B (Methodological), 13: 238-241. https://doi.org/10.1111/j.2517-6161.1951.tb00088.x . G. UNDY YULE, NOTES ON THE THEORY OF ASSOCIATION OF ATTRIBUTES IN STATISTICS, Biometrika, Volume 2, Issue 2, February 1903, Pages 121–134, https://doi.org/10.1093/biomet/2.2.121 . Matejka, J., &amp; Fitzmaurice, G. (2017). Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing. CHI 2017 Conference proceedings: ACM SIGCHI Conference on Human Factors in Computing Systems. Retrieved from https://www.autodeskresearch.com/publications/samestats. . library(data.table) library(ggplot2) library(datasauRus) options(repr.plot.width=8.9, repr.plot.height=6,units=&quot;cm&quot;) if(require(ggplot2)){ p &lt;- ggplot(simpsons_paradox, aes(x=x, y=y))+ geom_point(size=4,alpha=0.55)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~dataset, ncol=3) } p + theme_light(base_size = 20) . what you are seing is (from the description) &quot;A dataset demonstrating Simpson&#39;s Paradox with a strongly positively correlated dataset (simpson_1) and a dataset with the same positive correlation as simpson_1, but where individual groups have a strong negative correlation (simpson_2)&quot;. So is it possible to write a function to create random Yule-Simpson&#39;s paradox dataset? Let&#39;s try it (but first of all we add a regression line as shown in https://stackoverflow.com/a/15654715/6483091 and https://stackoverflow.com/a/37504482/6483091 . library(ggpmisc) options(repr.plot.width=8.9, repr.plot.height=6,units=&quot;cm&quot;) method &lt;- y ~ x pp &lt;- ggplot(simpsons_paradox, aes(x= x, y= y)) + geom_point(size=4,alpha=0.55) + facet_wrap(~dataset, ncol=3) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) pp + theme_light(base_size = 20) . the strategy that we will follow is simple. and it is again very &quot;brutal&quot; and not formal at all. the idea is . create a starting and ending x for the x y dataset we are creating | (add noise) | divide in n intervals/step the xend-xstart | create distributions (normal, uniform, gaussian,whatever) for each step | rotate all the distributions (simple trigonometry) the code is the following, but again plots will better explain the strategy Before implementing the step we try to see how to create a distribution and rotate it | library(data.table) library(foreach) library(ggpmisc) points_dist=100 theta=seq(-1,1,0.1) options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) x &lt;- rnorm(points_dist,0,1) y &lt;- rnorm(points_dist,0,0.2) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) m=3 xstart=1 xend=10 xseq &lt;- seq(xstart,xend,2) yseq &lt;- m*xseq library(foreach) xsimp &lt;- foreach(i=1:length(xseq)) %do% { xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { yseq[i]+yi } xysimp &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(xysimp) &lt;- c(&quot;x&quot;,&quot;y&quot;) method &lt;- y ~ x p2 &lt;- ggplot(xysimp, aes(x= x, y= y)) + geom_point(size=4,alpha=0.05) + geom_smooth(method = &quot;lm&quot;, formula = method, color = &quot;blue&quot;, size=1, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_light(base_size = 20) . Warning message in x * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in x * sin(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; Warning message in y * cos(pi * theta): &#34;longer object length is not a multiple of shorter object length&#34; . ok it seems to work. Let&#39;s wrap it in a function (we also add a set.seed in order to randomize each group) . library(data.table) library(foreach) #we now write everything in form of a function yulsim &lt;- function(m=3,xstart=1,xend=10,theta=-0.3,step=0.5,nfx=0.1,nfy=0.5,npoints=100,coeff=2){ m=m xstart=xstart xend=xend xseq &lt;- seq(xstart,xend,step) yseq &lt;- coeff + m*xseq xsimp &lt;- foreach(i=1:length(xseq)) %do% { set.seed(i*4) x &lt;- rnorm(npoints,0,nfx) xi &lt;- x*cos(pi*theta)-y*sin(pi*theta) xseq[i]+xi } ysimp &lt;- foreach(i=1:length(yseq)) %do% { set.seed(i*3) y &lt;- rnorm(npoints,0,nfy) yi &lt;- x*sin(pi*theta)-y*cos(pi*theta) yseq[i]+yi } ldat &lt;- data.table(xsimp,ysimp) dat &lt;- data.table(unlist(xsimp),unlist(ysimp)) colnames(dat) &lt;- c(&quot;x&quot;,&quot;y&quot;) my.list &lt;- list(&quot;lout&quot;=ldat,&quot;out&quot;=dat) return(my.list) } . a few more test with ggplot . options(repr.plot.width=8.9, repr.plot.height=6,units=&quot;cm&quot;) st1 &lt;- yulsim (m=-3,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) st2 &lt;- yulsim (m=-2,xstart=20,xend=80,theta=0.4,step=20,nfx=12,nfy=2,npoints=100,coeff=-5) ys1 &lt;- st1$out ys2 &lt;- st2$out ys1$set &lt;- &quot;ys_1&quot; ys2$set &lt;- &quot;ys_2&quot; ysset &lt;- rbind(ys1,ys2) p2 &lt;- ggplot(ysset, aes(x=x, y=y))+ geom_point(size=4,alpha=0.05)+ theme(legend.position = &quot;none&quot;)+ facet_wrap(~set, ncol=2) + geom_smooth(method = &quot;lm&quot;, formula = method, se = F) + stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), label.x.npc = &quot;right&quot;, label.y.npc = -1, formula = method, parse = TRUE, size = 6) p2 + theme_light(base_size = 20) . and everything seems to work fine. The function is quite brutal, we can indeed change also the distributions used, but it is very flexible and does its job. so now we can generate as much as we want y-s dataset .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/ys.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Anscombe's  quartet",
            "content": "TOC . can we create a function to recreate infinite Anscombe&#39;s quartet even with more points? | . update: for now I&#39;ve just created the 1,3 and 4 quartet. The second one should be not too difficult too to add. As you can see not all statistics are the same but the mean is. Still to tweak a bit but a good starting point. For a detailed description of Anscombe quartet see, F. J. &quot;Graphs in Statistical Analysis.&quot; The American Statistician 27, no. 1 (1973): 17-21. Accessed July 4, 2021. doi:10.2307/2682899. Let&#39;s start importing the data and plot them also we will add the regression labs . library(ggpmisc) library(data.table) library(ggplot2) library(datasauRus) library(patchwork) options(repr.plot.width=8.9, repr.plot.height=4.5,units=&quot;cm&quot;) summary(anscombe) # xi &lt;- (x*cos(pi*theta[i])-y*sin(pi*theta[i])) # yi &lt;- (x*sin(pi*theta[i])-y*cos(pi*theta[i])) npoints= 11 youtlier = 20 xoutlier = 10 xmin = 1 xmax = 10 ymin = -5 ymax = 5 plotreg &lt;- function(df){ formula &lt;- y ~ x ggplot(df, aes(x = x, y = y)) + geom_point(aes(size = 5),alpha = 0.3) + geom_smooth(method = &quot;lm&quot;, formula = formula, se = T) + #stat_poly_eq(aes(label = paste(..eq.label.., ..rr.label.., sep = &quot;~~~&quot;)), # label.x.npc = &quot;right&quot;, label.y.npc = 0.15, # formula = formula, parse = TRUE, size = 8)+ theme_light(base_size=14)+theme(legend.position = &quot;none&quot;) } multians &lt;- function (npoints= 11, youtlier = 20, xoutlier = 10, xmin = 1 , xmax = 10, ymin = -5, ymax = 5){ #plot4 x &lt;- c(rep(xmin,(npoints-1)),xoutlier) y &lt;- c(seq(ymin, ymax, length.out = (npoints-1)),youtlier) df &lt;- data.frame(x,y) colnames(df) &lt;- c(&quot;x&quot;,&quot;y&quot;) #plot1 #3 outlier myint &lt;- (xmin-xmax)/2 xnew &lt;- seq(mean(x)-myint,mean(x)+myint,length.out=npoints) new &lt;- data.frame(x=xnew) y1mod &lt;- predict(lm(y ~ x), data.frame(x=xnew), se.fit = TRUE) y1 &lt;- y1mod$fit s &lt;- sample(npoints,3) noise &lt;- rnorm(s,0,(ymax-ymin)/7) y1[s] &lt;- y1[s]+noise df1 &lt;- data.frame(xnew,y1) colnames(df1) &lt;- c(&quot;x&quot;,&quot;y&quot;) #plot3 #Set3 #1 outlier s &lt;- (2) noise &lt;- rnorm(1,0,(ymax-ymin)) y3 &lt;- y1 y3[s] &lt;- sum(y1)-sum(y3[-s]) y3[s] &lt;- y3[s]+noise df3 &lt;- data.frame(xnew,y3) colnames(df3) &lt;- c(&quot;x&quot;,&quot;y&quot;) # mylist=list(&quot;df4&quot;=df,&quot;df1&quot;=df1,&quot;df3&quot;=df3) return(mylist) } t1 &lt;- multians() t2 &lt;- multians() t3 &lt;- multians(npoints= 21) . x1 x2 x3 x4 y1 Min. : 4.0 Min. : 4.0 Min. : 4.0 Min. : 8 Min. : 4.260 1st Qu.: 6.5 1st Qu.: 6.5 1st Qu.: 6.5 1st Qu.: 8 1st Qu.: 6.315 Median : 9.0 Median : 9.0 Median : 9.0 Median : 8 Median : 7.580 Mean : 9.0 Mean : 9.0 Mean : 9.0 Mean : 9 Mean : 7.501 3rd Qu.:11.5 3rd Qu.:11.5 3rd Qu.:11.5 3rd Qu.: 8 3rd Qu.: 8.570 Max. :14.0 Max. :14.0 Max. :14.0 Max. :19 Max. :10.840 y2 y3 y4 Min. :3.100 Min. : 5.39 Min. : 5.250 1st Qu.:6.695 1st Qu.: 6.25 1st Qu.: 6.170 Median :8.140 Median : 7.11 Median : 7.040 Mean :7.501 Mean : 7.50 Mean : 7.501 3rd Qu.:8.950 3rd Qu.: 7.98 3rd Qu.: 8.190 Max. :9.260 Max. :12.74 Max. :12.500 . plotreg(t1$df4)+plotreg(t1$df1) plotreg(t1$df3)+plotreg(t2$df3) . summary(t1$df4) summary(t1$df1) summary(t1$df3) summary(t2$df4) summary(t2$df1) summary(t2$df3) . x y Min. : 1.000 Min. :-5.0000 1st Qu.: 1.000 1st Qu.:-2.2222 Median : 1.000 Median : 0.5556 Mean : 1.818 Mean : 1.8182 3rd Qu.: 1.000 3rd Qu.: 3.3333 Max. :10.000 Max. :20.0000 . x y Min. :-2.6818 Min. :-10.278 1st Qu.:-0.4318 1st Qu.: -3.182 Median : 1.8182 Median : 1.818 Mean : 1.8182 Mean : 1.757 3rd Qu.: 4.0682 3rd Qu.: 6.613 Max. : 6.3182 Max. : 13.655 . x y Min. :-2.6818 Min. :-10.278 1st Qu.:-0.4318 1st Qu.: -3.182 Median : 1.8182 Median : 1.818 Mean : 1.8182 Mean : 2.687 3rd Qu.: 4.0682 3rd Qu.: 6.613 Max. : 6.3182 Max. : 20.049 . x y Min. : 1.000 Min. :-5.0000 1st Qu.: 1.000 1st Qu.:-2.2222 Median : 1.000 Median : 0.5556 Mean : 1.818 Mean : 1.8182 3rd Qu.: 1.000 3rd Qu.: 3.3333 Max. :10.000 Max. :20.0000 . x y Min. :-2.6818 Min. :-6.293 1st Qu.:-0.4318 1st Qu.:-3.182 Median : 1.8182 Median : 2.062 Mean : 1.8182 Mean : 1.927 3rd Qu.: 4.0682 3rd Qu.: 6.818 Max. : 6.3182 Max. :10.879 . x y Min. :-2.6818 Min. :-6.293 1st Qu.:-0.4318 1st Qu.:-3.182 Median : 1.8182 Median : 2.062 Mean : 1.8182 Mean : 1.710 3rd Qu.: 4.0682 3rd Qu.: 6.625 Max. : 6.3182 Max. :10.879 . plotreg(t3$df1)+plotreg(t3$df3) summary(t3$df1) summary(t3$df3) . x y Min. :-3.0714 Min. :-9.0476 1st Qu.:-0.8214 1st Qu.:-4.0476 Median : 1.4286 Median : 1.9524 Mean : 1.4286 Mean : 0.8461 3rd Qu.: 3.6786 3rd Qu.: 5.1670 Max. : 5.9286 Max. :10.9524 . x y Min. :-3.0714 Min. :-9.0476 1st Qu.:-0.8214 1st Qu.:-4.0476 Median : 1.4286 Median : 1.9524 Mean : 1.4286 Mean : 0.6014 3rd Qu.: 3.6786 3rd Qu.: 4.9524 Max. : 5.9286 Max. :10.9524 .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "relUrl": "/r/ggplot/recipes/simpson/2021/07/04/anscombe.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "About different data same box plot",
            "content": "TOC . write a function for generating random group of data with (almost) same stats | . As in my previous post I was fascinated by the &quot;datasaurus&quot; (sets of data having same basic stats and also same boxplot). You can have a look at this page to find all details. Since the plot also looks a lot like a kind of diffraction pattern I tried a simple idea I had in mind. What will happen if I generate distributions with as mean the median, q1,q3,min and max of a &quot;reference&quot; dataset and I merge everything together? If I keep the everything &quot;symmetric enough&quot; (I know this is a term that does not exists) cuttin in half the distibution at the min and max I probably will obtain another &quot;equivalent&quot; dataset. . library(data.table) library(ggplot2) library(datasauRus) library(patchwork) library(foreach) summary(box_plots) . left lines normal right Min. :-9.76964 Min. :-9.769575 Min. :-9.76 Min. :-9.760 1st Qu.:-2.68999 1st Qu.:-2.689993 1st Qu.:-2.68 1st Qu.:-2.680 Median :-0.00999 Median :-0.007132 Median : 0.00 Median : 0.000 Mean :-1.17780 Mean :-0.831733 Mean : 0.00 Mean : 1.174 3rd Qu.: 2.67007 3rd Qu.: 2.670236 3rd Qu.: 2.68 3rd Qu.: 2.680 Max. : 9.75025 Max. : 9.756001 Max. : 9.76 Max. : 9.760 split Min. :-9.769886 1st Qu.:-2.689989 Median :-0.003099 Mean :-0.003060 3rd Qu.: 2.680000 Max. : 9.760000 . A simple start . Before creating a function with custom parameters we will start in the most simple way possible . in_dat &lt;- summary(box_plots$left) median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/20 npoints=100 d_median &lt;- rnorm(npoints,median_r,sd_r) d_q1 &lt;- rnorm(npoints,q1_r,sd_r) d_q3 &lt;- rnorm(npoints,q3_r,sd_r) d_min &lt;- rnorm(npoints,min_r,sd_r) d_max &lt;- rnorm(npoints,max_r,sd_r) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; max_r &amp; df_sim$sim&gt;min_r,] options(repr.plot.width=12, repr.plot.height=8) options(repr.plot.width=12, repr.plot.height=8) psim &lt;-ggplot(df_sim_sel, aes(x = 0, y = sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3.5) + theme_light(base_size=24) + xlim(-1, 1) bplot &lt;- data.frame(box_plots) p1 &lt;-ggplot(bplot, aes(x = 0, y = left)) + geom_jitter(alpha=0.05,size=3.5) + theme_light(base_size=24) + xlim(-1, 1) #summary(df_sim_sel$sim) p1 + psim . so the plot is almost there but the data are still not ok now we create a function, add points and create a bit of benchmarks and also plots.starting with the function . boxSim &lt;- function(npoints,med = median_r, q1 = q1_r, q3 = q3_r, mmin = min_r, mmax = max_r, sdr = c(2,2,2,2,2)) { d_median &lt;- rnorm(npoints,med,sdr[1]) d_q1 &lt;- rnorm(npoints,q1,sdr[2]) d_q3 &lt;- rnorm(npoints,q3,sdr[3]) d_min &lt;- rnorm(npoints,mmin,sdr[4]) d_max &lt;- rnorm(npoints,mmax,sdr[5]) sim &lt;- c(d_median,d_q1,d_q3,d_min,d_max) lab_median &lt;- rep(&quot;median&quot;,npoints) lab_q1 &lt;- rep(&quot;q1&quot; ,npoints) lab_q3 &lt;- rep(&quot;q3&quot; ,npoints) lab_min &lt;- rep(&quot;min&quot; ,npoints) lab_max &lt;- rep(&quot;max&quot; ,npoints) sim_lab &lt;- c(lab_median,lab_q1,lab_q3,lab_min,lab_max) df_sim &lt;- data.frame(sim,sim_lab) df_sim_sel &lt;- df_sim[df_sim$sim &lt; mmax &amp; df_sim$sim&gt;mmin,] return(df_sim_sel) } . now everything is more flexible since we can give each of the median,q1,q3,min,max its own variance and create even more combinations (keeping &quot;everything symmetric&quot;) . median_r &lt;- in_dat[3] q1_r &lt;- in_dat[2] q3_r &lt;- in_dat[5] min_r &lt;- in_dat[1] max_r &lt;- in_dat[6] sd_r &lt;- abs(max_r-min_r)/10 n_points = c(100,1000,50000) t100 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t1k &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t10k &lt;- boxSim(10000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t50k &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t100_2 &lt;- boxSim(100,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t1k_2 &lt;- boxSim(1000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) t10k_2 &lt;- boxSim(10000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) t50k_2 &lt;- boxSim(50000,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) ptest &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5) + theme_void() + xlim(-1, 3) legend &lt;- cowplot::get_legend(ptest) datr &lt;- data.table(box_plots$left) colnames(datr) &lt;- c(&quot;y&quot;) pref &lt;- ggplot(datr, aes(x = 1, y = y )) + geom_jitter(alpha=0.5,size=3.5) + theme_light(base_size=24) pt100 &lt;-ggplot(t100, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5,size=3.5) + theme_light(base_size=24) pt1k &lt;-ggplot(t1k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.05,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pt10k &lt;-ggplot(t10k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.05,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pt50k &lt;-ggplot(t50k, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.2,size=3.5) + theme_light(base_size=24) pt100_2 &lt;-ggplot(t100_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.5 ,size=3.5) + theme_light(base_size=24) pt1k_2 &lt;-ggplot(t1k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.05,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pt10k_2 &lt;-ggplot(t10k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.05,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pt5k_2 &lt;-ggplot(t50k_2, aes(x = 1, y =sim, color=sim_lab)) + geom_jitter(alpha=0.2) + theme_light(base_size=24) library(patchwork) pt100 + pt1k + pt10k pt100_2 + pt1k_2 + pt10k_2 . pb1 &lt;- pref + geom_boxplot(lwd=1, alpha=0.5) pb2 &lt;- ggplot(t100, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.5,,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pb3 &lt;- ggplot(t1k, aes(x = 1, y =sim)) + geom_boxplot(lwd=1) + geom_jitter(alpha=0.05,,size=3.5) + theme_light(base_size=24) + theme(legend.position = &quot;none&quot;) pb1+pb2+pb3 . refdf &lt;- data.frame(unclass(summary(datr))) colnames(refdf) &lt;- (&quot;refdf&quot;) library(foreach) test &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.1,0.2,0.2,2,2)) res &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res.dat &lt;- data.frame(res) colnames(res.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r1 &lt;- data.frame(refdf,res.dat) test2 &lt;- foreach(i=seq(1000,20000,5000)) %do% boxSim(i,in_dat[3],in_dat[2], in_dat[5],in_dat[1],in_dat[6],c(0.2,0.2,0.2,3,3)) res2 &lt;- lapply(seq(1,length(test)), function(x) summary(test[[x]]$sim)) res2 &lt;- lapply(seq(1,length(test)), function(x) data.frame(unclass(summary(test2[[x]]$sim)), check.names = FALSE, stringsAsFactors = FALSE) ) res2.dat &lt;- data.frame(res2) colnames(res2.dat) &lt;- as.character(paste0(&quot;npoints_&quot;,seq(1000,20000,5000))) r2 &lt;- data.frame(refdf,res.dat) r1 r2 . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.76692838 | -9.76961475 | -9.769568001 | -9.769261e+00 | . X.11st Qu.:-2.68999 | -2.68136806 | -2.69428591 | -2.688846175 | -2.689685e+00 | . X.2Median :-0.00999 | -0.01074982 | -0.01357824 | -0.009647720 | -1.002458e-02 | . X.3Mean :-1.17780 | 0.02634308 | -0.01844466 | -0.006731544 | 3.254214e-05 | . X.43rd Qu.: 2.67007 | 2.65996591 | 2.66339999 | 2.667832211 | 2.667141e+00 | . X.5Max. : 9.75025 | 9.74691002 | 9.74856584 | 9.750000660 | 9.750033e+00 | . A data.frame: 6 × 5 refdfnpoints_1000npoints_6000npoints_11000npoints_16000 . &lt;chr&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt; . XMin. :-9.76964 | -9.76692838 | -9.76961475 | -9.769568001 | -9.769261e+00 | . X.11st Qu.:-2.68999 | -2.68136806 | -2.69428591 | -2.688846175 | -2.689685e+00 | . X.2Median :-0.00999 | -0.01074982 | -0.01357824 | -0.009647720 | -1.002458e-02 | . X.3Mean :-1.17780 | 0.02634308 | -0.01844466 | -0.006731544 | 3.254214e-05 | . X.43rd Qu.: 2.67007 | 2.65996591 | 2.66339999 | 2.667832211 | 2.667141e+00 | . X.5Max. : 9.75025 | 9.74691002 | 9.74856584 | 9.750000660 | 9.750033e+00 | . with this very brutal test we can see that 1000 points are enough to obtain an acceptable random dataset with predefined stats. Also the fun is that changing seeds everytime we have a different dataset.so the mainly advantages are . extremely fast | can generate dataset with same stats as a reference dataset (the generated set can have same number of points &gt; or &lt;) | can several kind of distributions (need to keep data &quot;symmetry&quot;) Probably also this can be a starting point for applying a simulated annealing after. Or this very simple stragegy can be employed for other problems. | . NOTE: this example was done for the left subset of the box_plot dataset. The same stragety can be applied for all the subsets .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/samedata.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/samedata.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Recipes for Exploratory Data Analysis by means of simple plots",
            "content": "TOC . how to simulate simple data sets | setup a template for plots | create a line plot | add a jiiter plot to the base plot | increase the dataset dimension for creating a scatter plot | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # loading required libraries for this notebook #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #loading libraries library(ggplot2) library(gridExtra) library(data.table) library(RColorBrewer) library(ggrepel) library(patchwork) . Which plot to choose? . The answer depend on your data. Depending on the kind of relation you would like to highlight there are different plots that can be useful. In my workflow generally the first think I need to check is . presence of a changing in time of one (or multiple) variables | check if the data follow a distribution | check the presence of a linear correlation between the variables | For this purpose we can use . time series plots | distribution plots | correlation plots | First of all we generate some data . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # creating a very simple dataframe #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Parameters x_min &lt;- 0 x_max &lt;- 10 x_step &lt;- 0.01 y_mean &lt;- 0.5 y_sd &lt;- 0.25 y_min &lt;- -1 y_max &lt;- 1 x &lt;- seq(x_min,x_max,x_step) # Variables var_random &lt;- runif(x,y_min,y_max) var_norm &lt;- rnorm(x,y_mean,y_sd) var_sin &lt;- sin(x) # Data.frame df &lt;- data.frame (x,var_random,var_norm,var_sin) dt &lt;- data.table(df) # Melt dtm &lt;- melt(dt, id.vars=&quot;x&quot;) head(dtm) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° . A data.table: 6 × 3 xvariablevalue . &lt;dbl&gt;&lt;fct&gt;&lt;dbl&gt; . 0.00 | var_random | -0.541030637 | . 0.01 | var_random | -0.485715914 | . 0.02 | var_random | 0.588714651 | . 0.03 | var_random | 0.002162422 | . 0.04 | var_random | -0.721160703 | . 0.05 | var_random | 0.154144957 | . notes about the code A few comments on the code. First of all we setup the min of x and y and also a few parameters that will e used to generate the data. as a second step we use the functions runif,rnorm and sin to create a random variable, a uniformly distributed variable and a sinusoid. We use the function data.frame to put togheter the x and vars, we then transform everything in a data.table since we need to use the function melt from the data.table library. In this case the id of each variable corrensponds to the x and so in the melt function we used as a parameter the id.vars=x . The previous code create a personalised theme replacing the settings that can be found in the theme_minimal from ggplot. For doing that we use the command %+replace%. We just changed some text options plot, but here you can insert all the customization you want (see the ggplot reference here. Now that we have set the theme for our plot we will plot the three variables. Since we only have 3 variables we can create a line plot for each of the variable and using the library patchwork we put all of the plots together . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Line plot #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) p &lt;- ggplot(dtm[variable==&quot;var_sin&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable),size=3) + theme_light(base_size=20) + theme(legend.position = &quot;none&quot;) p1 &lt;- ggplot(dtm[variable==&quot;var_norm&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable)) + theme_light(base_size=20) + theme(legend.position = &quot;none&quot;) p2 &lt;- ggplot(dtm[variable==&quot;var_random&quot;], aes(x = x, y = value, group=variable)) + geom_line(aes(linetype=variable,color=variable)) + theme_light(base_size=20) + theme(legend.position = &quot;none&quot;) p p1 p2 . So what does the previous lines of code works. First of all we create an object p. For ggplot every plot is just an object that we can recall later. This is very important since we can put plots in a list, we can write functions that can generate plots and in a few lines and we can take advantage of how R deals with objects also (I&#39;m using the term object with large acception here and not in a stricly language meaaning). We invock a ggplot and we tell that he should consider the data dtm as source for the plot. Since we do not want to plot all the variables we select only the variable_sin. Then we need to specify the x and y and also if we want any grouping variable. Everything included in the parenthesis after the aes() takes care of it. Now the important part: adding a line plot we use the geom_line (if you stop here and try to get a plot you will only get an empty canvas + the x and y axis and labels). This will create the line plot and finally we use the theme for the plot we just created. What does our plots tell us? We can spot without problem the sinusoid. While the other data looks noisy and random. Is there any kind of distribution in the values of our variables? Let&#39;s find it our creating histograms of the values of the variables in exam. . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Histogram plot #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° p3 &lt;- ggplot(dtm[variable==&quot;var_sin&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_light(base_size=20) p4 &lt;- ggplot(dtm[variable==&quot;var_norm&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_light(base_size=20) p5 &lt;- ggplot(dtm[variable==&quot;var_random&quot;], aes(y = value, group=variable)) + geom_histogram(bins=20) + theme_light(base_size=20) p3 + p4 + p5 . notes on the code. Since dtm is a data.table we can use the following synthax dtm[variable==&quot;var_sin&quot;] to select only the variable we would like to plot. We add an histogram and with the options bins=20,R will take care of splitting the distributions in 20 bins. What do the plots tell us? It is easy to spot at a glance that we have one of the variable with a normal distribution while the other are not. The sin(x) looks as expected with higher frequencies of values at -1 and 1 and the noise variable has does not show any kind of distribution. . Now we will use another kind of plot to see how the data are distributed. What is called a jiiter plot . pj1 &lt;- ggplot(dtm, aes(x=variable,y = value, group=variable)) + geom_jitter(position = position_jitter(0.1),alpha=0.1,, size = 3) + theme_light(base_size=20) pj1 . notes on the code: in this case we just used all the dataframe with the variable as x and the y as the value. since we have lots of points we used an alpha value of 0.1 in order to have a nice effect on the plot. About the results. the concentration of points (absent in the first case, concentrated on a mean value, at the border for the sinusoidal values) gives us a perfect glance of the distribution of the values. Finally in order to explore Let&#39;s add a second se of &quot;measurements&quot; for each variable to the dataset previously created and let&#39;s plot them . # new variables #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° var_random2 &lt;- runif(x,y_min,y_max) var_norm2 &lt;- rnorm(x,y_mean,y_sd) var_sin2 &lt;- sin(x) + rnorm(x,0,0.1) . At first we will plot them and add them to the previous plot . p7 &lt;- p + geom_line(aes(y=var_sin2, color=&quot;blue&quot;),size=1) p8 &lt;- p1 + geom_line(aes(y=var_norm2, color=&quot;blue&quot;)) p9 &lt;- p2 + geom_line(aes(y=var_random2, color=&quot;blue&quot;)) p7 + theme(legend.position = &quot;none&quot;) p8 + theme(legend.position = &quot;none&quot;) p9 + theme(legend.position = &quot;none&quot;) . we could have changed the dataframe and add the new columns but the versatility of ggplot let us add a new layer of plot and also specify the new color we would like to use for it. Are these &quot;second measurements&quot;s correlated in comparison with the previous one? We can check it using a scatter plot. ggplot can help us with the command geom points but this time for sake of clarity we will first merge the new data with the dataframe . df2&lt;- data.frame(df,var_sin2,var_norm2,var_random2) dt2 &lt;- data.table(df2) p10 &lt;- ggplot(dt2) + geom_point(aes(x=var_sin,y=var_sin2),size=5,alpha=0.5) + theme_light(base_size=20) p11 &lt;- ggplot(dt2) + geom_point(aes(x=var_norm,y=var_norm2),size=5,alpha=0.5) + theme_light(base_size=20) p12 &lt;- ggplot(dt2) + geom_point(aes(x=var_random,y=var_random2),size=5,alpha=0.5)+ theme_light(base_size=20) p10 p11 p12 . A few notes. We did not use melt since we just needed to select the cols from our newly created dataframe. (If needed a melt data.table can be reshape using the command dcast) We plotted them in pairs because we wanted to see if the &quot;first measurement&quot; was in some way correlated to the &quot;second one&quot; In the first plot we&#39;ve seen the pair of sinusoidal variables. We creaed them as correlated and in fact if we plot one vs the other we can see that the points lie on the bisect of the I and IV quadrant. They are positively lineary correlated. Then we have the norm variables. both of them are created at taking random numbers from a normal distribution. Finally the random vars. totally random and no correlation between them as expected. The aspect of the plot was changed in order to give more space to the plot .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/eda.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/eda.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Don't trust boxplot",
            "content": "TOC . write a function for generating data | use melt for rearranging data | create a base plot | add a boxplot to the base plot | add a jiiter plot to the base plot | create a figure for explaining the box plot (the fun part of this post) | create another dataset | add boxplot + jiiter plot | what&#39;s happening? | . #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # loading required libraries for this notebook #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #loading libraries library(ggplot2) library(gridExtra) library(data.table) library(RColorBrewer) library(ggpubr) library(rstatix, warn.conflicts = FALSE) library(ggrepel) library(ggpubr) library(patchwork) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # creating a function for generating a dataset #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # function for generating data with custom number of rows, means and sds simpleDataset &lt;- function(number_of_rows,means,sds) { l &lt;- length(means) res &lt;- lapply(seq(1:l),function(x) eval( parse( text=paste(&quot;rnorm(&quot;,number_of_rows,&quot;,&quot;,means[x],&quot;,&quot;,sds[x],&quot;)&quot;,sep=&quot;&quot;)) ) ) dat &lt;- data.frame((sapply(res,c))) id &lt;- rownames(dat) dat &lt;- cbind(id=id,dat) dt &lt;- data.table(dat) return(dt) } dat1 &lt;- simpleDataset(number_of_rows=100, means=runif(10,100,150), sds=runif(10,10,40)) outliers &lt;- simpleDataset(number_of_rows=5, means=runif(10,60,80), sds=runif(10,10,10)) dato &lt;-rbind(dat1,outliers) dt.melt &lt;- melt(dat1, id.vars=&quot;id&quot;) colnames(dt.melt) &lt;- c(&quot;id&quot;,&quot;category&quot;,&quot;var1&quot;) dt.melt$ncat &lt;- as.numeric(dt.melt$category) #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° # Jiitter plots + boxplot + brackets #+++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++°+++++++++° #setting up dimensions options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) #adding jiitter plot p &lt;- ggplot(dt.melt,aes(x=factor(ncat),y=var1)) + geom_jitter(position = position_jitter(0.15),alpha=0.5,size = 3) + geom_boxplot(alpha = 0,lwd=0.2) + theme_minimal(base_size =24) p +theme_light(base_size=24) . So for now everything on track. We created a dataset using a custom function. 10 variables with 100 points each and them we plot them using scatter plots. Before plotting a few more data we need to answer the question How are boxplot constructed? (warning: shameless self-promotion ahead) First of all you can check on my book/ebook https://amzn.com/B08W8W5WSF Now it starts the fun part we will recreate a plot on the anatomy of a boxplot (see here) using ggplot. . # y &lt;- c(60,63,105,155,rnorm(100,80,25)) box &lt;- ggplot() + theme_void() + geom_boxplot(aes(x=0,y=y),width=1,notch = FALSE,lwd=2) + theme(legend.position = &quot;none&quot;) + lims(x=c(-2,2)) #how can we get out data? using the function ggplot_build() #need to change it to a data.frame and rename cols box_data &lt;- (ggplot_build(box)$data)[[1]] box_data bdata &lt;- data.frame(t(box_data[c(1,2,3,4,5,14)])) colnames(bdata) &lt;- c(&quot;y&quot;) #we need to transpose the data and convert them to a data frame #now we extract the ourliers outl &lt;- data.frame(box_data$outliers) colnames(outl) &lt;- c(&quot;outl&quot;) #now that I got the data I plot everything with labels p2 &lt;- box + geom_text (data=bdata,aes( x=1.5, y=y, label = c(&quot;min (no outliers)&quot;,&quot;Lower Q&quot;,&quot;Median&quot;,&quot;Upper Q&quot;,&quot;max&quot;,&quot;outliers&quot;)),size=8) + geom_segment(data=bdata, aes(x = 0.8, y = y, xend = 0.6, yend =y),lwd=1) #since we have created the dataset WITH outliers we include labels also for them #if your dataset has no outliers you need to commet this part out p2 + geom_text_repel(data=outl,aes(x=0.1, y=outl,label=format(round(outl, 2), nsmall = 2)),size=6) . A data.frame: 1 × 26 yminlowermiddleupperymaxoutliersnotchuppernotchlowerxflipped_aes...xidnewxnew_widthweightcolourfillsizealphashapelinetype . &lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;list&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;lgl&gt;...&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;dbl&gt;&lt;chr&gt;&lt;chr&gt;&lt;dbl&gt;&lt;lgl&gt;&lt;dbl&gt;&lt;chr&gt; . 27.14312 | 61.85538 | 74.33114 | 93.25041 | 127.1763 | 155 | 79.19523 | 69.46705 | 0 | FALSE | ... | 1 | 0 | 1 | 1 | grey20 | white | 2 | NA | 19 | solid | . notes on the code: we create our variable y with rnorm and we add a few outliers by hand then we create the boxplot with an empty theme using theme_void(). The funny part start when we ask ggplot to show how the plot was built with the ggplot_build. We then need to rotate (t) the selected columns c(1,2,3,4,5,14) ,convert the results into a data.frame, rename the columns (colnames) and then use them (our y) to add labvels to our plot using geom_text . So the bound of the box refers to upper and lower quartile. The lower quartile splits off the lowest 25% of the data (also called 25% percentile) while the third quartile splits off the highest 25% of data from the lowest 75% (75% percentile). But what is a quartile? when a set of n measurements of the variable x has been arranged in order of magnitude the pth percentile is the value of x greater than p of the measurements. The 25th and 75th percentile are called the lower and upper quartiles and the 50th percentile is the median of the dataset. the IQR interquartile range (IQR) for a set of measurement is the difference between the upper and lower quartile . Another representation of boxplot can also include notch. the default is not to visualuize them but just adding notch=true to the previous plot we will do the trick . boxnotch &lt;- ggplot() + theme_void() + geom_boxplot(aes(x=0,y=y),width=1,notch = TRUE,lwd=2) + theme(legend.position = &quot;none&quot;) + lims(x=c(-2,4)) notchdata &lt;- data.frame(t(box_data[c(7,8)])) colnames(notchdata) &lt;- c(&quot;y_notch&quot;) #we need to transpose the data and convert them to a data frame #now that I got the data I plot everything with labels p3 &lt;- boxnotch + geom_segment(data=notchdata, aes(x = 0.8, y = mean(y_notch), xend = 0.6, yend = y_notch ),lwd=1) p4 &lt;- p3 + annotate(geom=&quot;text&quot;, x=2.5, y= mean(notchdata$y_notch), label=&quot;notch (95% confidence ninterval of median)&quot;,size=10) p4 . so having a look at the the page we can see that the following case can happen. we will load the dataset from the datasauRus package . What&#39;s happening? . options(repr.plot.width=8.9, repr.plot.height=8.9,units=&quot;cm&quot;) library(datasauRus) summary(box_plots) p1 &lt;-ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_jitter(alpha=0.05) + theme_void() p2 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values))+ geom_boxplot(lwd=1) + theme_void() p1+p2 . left lines normal right Min. :-9.76964 Min. :-9.769575 Min. :-9.76 Min. :-9.760 1st Qu.:-2.68999 1st Qu.:-2.689993 1st Qu.:-2.68 1st Qu.:-2.680 Median :-0.00999 Median :-0.007132 Median : 0.00 Median : 0.000 Mean :-1.17780 Mean :-0.831733 Mean : 0.00 Mean : 1.174 3rd Qu.: 2.67007 3rd Qu.: 2.670236 3rd Qu.: 2.68 3rd Qu.: 2.680 Max. : 9.75025 Max. : 9.756001 Max. : 9.76 Max. : 9.760 split Min. :-9.769886 1st Qu.:-2.689989 Median :-0.003099 Mean :-0.003060 3rd Qu.: 2.680000 Max. : 9.760000 . Solutions? . We can see that plotting the raw points even for hundreds of points works and represent well our data. In this case adding notch does not solve the problem. Other kind of plot get not fooled by our data as it can be seen in the following figure . options(repr.plot.width=12, repr.plot.height=12) pnotch &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_boxplot(notch=TRUE,lwd=1) + ggtitle(&quot;(notch=TRUE)&quot;) + theme_void() pjitter &lt;-ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_jitter(alpha=0.05) + ggtitle(&quot;geom_jitter&quot;) + theme_void() pviolin &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_violin(lwd=1) + ggtitle(&quot;geom_violin&quot;) + theme_void() pnotch + pjitter + pviolin . Other packages . beeswarm plot ggbeeswarm [https://github.com/eclarke/ggbeeswarm] (and here the things start getting artistic too!) (note: not all representation for this dataset work due to the number of points) | library(ggbeeswarm) p_qrandom0 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05) + ggtitle(&quot;quasi_random&quot;) + theme_void(base_size=20) #p_qrandom0 p_qrandom1 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukey&quot;) + ggtitle(&quot;Tukey&quot;) + theme_void(base_size=20) #p_qrandom1 p_qrandom2 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukeyDense&quot;) + ggtitle(&quot;Tukey + density&quot;) + theme_void(base_size=20) #p_qrandom2 p_qrandom3 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;tukeyDense&quot;) + ggtitle(&quot;Banded frowns&quot;) + theme_void(base_size=20) #p_qrandom3 p_qrandom4 &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_quasirandom(alpha=0.05,method = &quot;frowney&quot;) + ggtitle(&quot;Banded smiles&quot;) + theme_void(base_size=20) #p_qrandom4 #too many points #p_beeswarm &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + #geom_beeswarm(alpha=0.05) + ggtitle(&quot;beeswarm&quot;) + #theme_void() p_qrandom0 + p_qrandom1+p_qrandom2 . you can halso mix plot a useful package for that is gghalves that you can find here . library(gghalves) point_half &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_half_point(alpha=0.05) +theme_void(base_size=20) violin_half &lt;- ggplot(stack(box_plots), aes(x = ind, y = values)) + geom_half_violin() +theme_void(base_size=20) point_half + violin_half . finally a very useful package, also my favorite one for EDA ggstatplotthat you can find here that calculate also a lot of useful stats and combine different kind of plot in one plot . library(ggstatsplot) stackbox &lt;- stack(box_plots) pstack &lt;- ggbetweenstats( data = stackbox, x = ind, y = values, ) pstack + theme(text = element_text(size = 22), plot.subtitle = element_text(size = 20), legend.title = element_text(size = 22), legend.text = element_text(size = 22)) .",
            "url": "https://jojosgithub.github.io/blog/r/ggplot/recipes/2021/06/18/boxplot.html",
            "relUrl": "/r/ggplot/recipes/2021/06/18/boxplot.html",
            "date": " • Jun 18, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a researcher at the National Research Council of Italy at the “Giulio Natta” Institute of Chemical Sciences and Technologies (Scitec-Cnr).I started to be interested in multivariate statistics techniques applied to data from physic-chemical analysis methods 15 years ago during my Ph.D. and to apply it to material science ever since. Enthusiast about programming in R and Python in order to write tools for everyday laboratory activities. FOSS advocate. Messy coder. I’ve written also a book on this topic: “Statistical and Multivariate Analysis in Material Science” that you can find here https://amzn.com/B08W8W5WSF .",
          "url": "https://jojosgithub.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jojosgithub.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}